{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crescendonow/thai_geoparsing/blob/main/toponym_colab/IJG_2_CRF_attacut_Quadigram_PartOfGazetteer%2BExactMatch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "!pip install pickle-mixin\n",
        "!pip install sklearn_crfsuite\n",
        "!pip install pythainlp[full]"
      ],
      "metadata": {
        "id": "6bc8Htxw3MEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1IFvYbu24yw"
      },
      "outputs": [],
      "source": [
        "#library for use\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "import pickle\n",
        "import codecs\n",
        "\n",
        "#nlp library\n",
        "from pythainlp import word_tokenize, Tokenizer\n",
        "from pythainlp.tag import pos_tag, pos_tag_sents\n",
        "from pythainlp.corpus.common import thai_stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "#Mange data with scikit-learn\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import CRF\n",
        "from sklearn_crfsuite import scorers,metrics\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_validate, train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbaFPRe_4yN2",
        "outputId": "808274df-bfe8-4ec0-9ff8-69f061a6ba39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9eJgS3A24yz"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/1.Tokennization/train_dn.data', 'rb') as token:\n",
        "    train_data = pickle.load(token)\n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/1.Tokennization/test_attacut_cl.data', 'rb') as token2:\n",
        "    test_data = pickle.load(token2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/acp_attacut.data', 'rb') as acp:\n",
        "    academic = pickle.load(acp)\n",
        "    academic = set(academic)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/acp_full.data', 'rb') as acpfull:\n",
        "    academic_full = pickle.load(acpfull)\n",
        "    academic_full = set(academic_full)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/admin_attacut.data', 'rb') as admin:\n",
        "    admin = pickle.load(admin)\n",
        "    admin = set(admin)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/bsn_attacut.data', 'rb') as bsn:\n",
        "    bsn = pickle.load(bsn)\n",
        "    bsn = set(bsn)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/bsn_full.data', 'rb') as bsnfull:\n",
        "    bsn_full = pickle.load(bsnfull)\n",
        "    bsn_full = set(bsn_full)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/fplace_attacut.data', 'rb') as fplace:\n",
        "    fplace = pickle.load(fplace)\n",
        "    fplace = set(fplace)\n",
        "\n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/gov_attacut.data', 'rb') as gov:\n",
        "    gov = pickle.load(gov)\n",
        "    gov = set(gov)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/gov_full.data', 'rb') as govfull:\n",
        "    gov_full = pickle.load(govfull)\n",
        "    gov_full = set(gov_full)\n",
        "\n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/hp_attacut.data', 'rb') as hp:\n",
        "    hp = pickle.load(hp)\n",
        "    hp = set(hp)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/hp_full.data', 'rb') as hpfull:\n",
        "    hp_full = pickle.load(hpfull)\n",
        "    hp_full = set(hp_full)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/mon_attacut.data', 'rb') as mon:\n",
        "    mon = pickle.load(mon)\n",
        "    mon = set(academic)\n",
        "\n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/nat_attacut.data', 'rb') as nat:\n",
        "    nat = pickle.load(nat)\n",
        "    nat = set(nat)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/rct_attacut.data', 'rb') as rct:\n",
        "    rct = pickle.load(rct)\n",
        "    rct = set(rct)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/rct_full.data', 'rb') as rctfull:\n",
        "    rct_full = pickle.load(rctfull)\n",
        "    rct_full = set(rct_full)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/res_attacut.data', 'rb') as res:\n",
        "    res = pickle.load(res)\n",
        "    res = set(res)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/res_full.data', 'rb') as resfull:\n",
        "    res_full = pickle.load(resfull)\n",
        "    res_full = set(res_full)\n",
        "\n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/rp_attacut.data', 'rb') as rp:\n",
        "    rp = pickle.load(rp)\n",
        "    rp = set(rp)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/rp_full.data', 'rb') as rpfull:\n",
        "    rp_full = pickle.load(rpfull)\n",
        "    rp_full = set(rp_full)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/store_attacut.data', 'rb') as store:\n",
        "    store = pickle.load(store)\n",
        "    store = set(store)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/store_full.data', 'rb') as storefull:\n",
        "    store_full = pickle.load(storefull)\n",
        "    store_full = set(store_full)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/tran_attacut.data', 'rb') as tran:\n",
        "    tran = pickle.load(tran)\n",
        "    tran = set(tran)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/tran_full.data', 'rb') as tranfull:\n",
        "    tran_full = pickle.load(tranfull)\n",
        "    tran_full = set(tran_full)\n",
        "        \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/poiall_attacut.data', 'rb') as poiall:\n",
        "    poiall = pickle.load(poiall)\n",
        "    poiall = set(poiall)\n",
        "    \n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/2.Gazetteer/poi_full.data', 'rb') as poi_full:\n",
        "    poi_full = pickle.load(poi_full)\n",
        "    poi_full = set(poi_full)"
      ],
      "metadata": {
        "id": "QATlkVGV8gRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g79O3gv24y0"
      },
      "outputs": [],
      "source": [
        "#Create feature function list\n",
        "def prep_list(word):\n",
        "    prep_list = set(['อยู่','อยู่ที่','ถึง','ไปถึง','มาถึง','มุ่งหน้า','เข้าสู่','เส้น','เยื้อง','ถัดไป','ถัดจาก','ตรงข้าม','ตรงกับ','ตรงข้ามกับ',\n",
        "                'ติด','ติดกับ','ข้าง','ข้างหน้า'])\n",
        "    if word in prep_list:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def prefix_nat(word):\n",
        "    p_nat = set(['ภู','ภูเขา','ดอย','ทะเล','คลอง','แม่น้ำ','ห้วย','บึง'])\n",
        "    if word in p_nat:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def prefix_res(word):\n",
        "    p_res = set(['หมู่บ้าน','ม.','บ้าน','คอนโด','อาร์ตเมนต์'])\n",
        "    if word in p_res:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def prefix_rp(word):\n",
        "    p_rp  = set(['วัด','มัสยิด','โบสถ์','คริสตจักร'])\n",
        "    if word in p_rp:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def prefix_acp(word):\n",
        "    p_acp = set(['โรงเรียน','รร.','วิทยาลัย','มหาวิทยาลัย','ม.','สถาบัน','ราชภัฏ'])\n",
        "    if word in p_acp:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def prefix_hp(word):\n",
        "    p_hp = set(['โรงพยาบาล','คลินิค','ศูนย์ฑันตกรรม','โรงยิม','ส่งเสริม','สุขภาพ'])\n",
        "    if word in p_hp:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def prefix_tran(word):\n",
        "    p_tran = set(['สถานี','สถานีรถไฟ','บีทีเอส','bts','สนามบิน','ท่าอากาศยาน','ท่าเรือ'])\n",
        "    if word in p_tran:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def prefix_store(word):\n",
        "    p_store = set(['ร้าน','ตลาด'])\n",
        "    if word in p_store:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def prefix_market(word):\n",
        "    p_mkt = set(['ตลาด','ตลาดนัด'])\n",
        "    if word in p_mkt:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def prefix_rt(word):\n",
        "    p_rt = set(['ร้าน','ร้านอาหาร','ศูนย์อาหาร','ภัตตาคาร','ห้องอาหาร'])\n",
        "    if  word in p_rt:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def prefix_dep(word):\n",
        "    p_dep = set(['ห้างสรรพสินค้า','ศูนย์การค้า','เดอะมอลล์','เซ็นทรัล','บิ๊กซี','โลตัส'])\n",
        "    if word in p_dep:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def prefix_bsn(word):\n",
        "    p_bsn = set(['อาคาร','ตึก','สำนักงาน','บริษัท'])\n",
        "    if word in p_bsn:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def prefix_gov(word):\n",
        "    p_gov = set(['กระทรวง','ทบวง','กรม','ค่าย','ศาล','ศูนย์ราชการ','ศาลาว่าการ','สำนัก'])\n",
        "    if word in p_gov:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def prefix_rct(word):\n",
        "    p_rct = set(['สนามกีฬา','สวนสัตว์','สวนสนุก','สวนสาธารณะ','โรงภาพยนต์','โรงละคร','สตูดิโอ','พิพิธภัณฑ์'])\n",
        "    if word in p_rct:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def prefix_mon(word):\n",
        "    p_mon = set(['อนุเสาวรีย์','วงเวียน','หอนาฬิกา'])\n",
        "    if word in p_mon:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def prefix_road(word):\n",
        "    p_road = set(['ถนน','ถ.','ซอย','ซ.','ทางหลวง','ทางหลวงแผ่นดิน'])\n",
        "    if word in p_road:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def prefix_admin(word):\n",
        "    p_admin = set(['ตำบล','ต.','อำเภอ','อ.','จังหวัด','จ.','ประเทศไทย'])\n",
        "    if word in p_admin:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def suffix_res(word):\n",
        "    s_res = set(['ภิรมย์','ธานี','วิลเลจ','โฮม','การ์เดนโฮม','เลควิว','ธารา','ปาร์ควิว','วิลล์','เฮาส์'])\n",
        "    if word in s_res:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def suffix_rp(word):\n",
        "    s_rp = set(['วนาราม','วราราม','วรวิหาร','วรมหาวิหาร','อารามหลวง'])\n",
        "    if word in s_rp:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def suffix_acp(word):\n",
        "    s_acp = set(['วิทยา','วิทยาลัย','วิทยาคม','วิทยายน','วิทยาคาร','พิทยา','พิทยาลัย','พิทยาคม','ศึกษา','ศึกษาลัย'])\n",
        "    if word in s_acp:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def suffix_store(word):\n",
        "    s_store = set(['สโตร์','store','มาร์เก็ต','market'])\n",
        "    if word in s_store:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def suffix_rt(word):\n",
        "    s_res = set(['ภัตตาคาร','เรสเตอรองค์','restuarant','คาเฟ่','คาเฟ','cafe'])\n",
        "    if word in s_res:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def suffix_dep(word):\n",
        "    s_dep = set(['ดีพาร์ทเมนต์สโตร์','departmentstore','ซุเปอร์สโตร์','superstore','ซูปเปอร์เซ็นเตอร์','supercenter','เซ็นเตอร์','เซนเตอร์','center'])\n",
        "    if word in s_dep:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "#feature from word space \n",
        "def is_space(word):\n",
        "    if word == ' ' or word == '\\t' or word == '':\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "#len feature\n",
        "def long_word(word):\n",
        "    l_word = len(word)\n",
        "    return l_word\n",
        "\n",
        "#feature shape\n",
        "def word_shape(word):\n",
        "    t1 = re.sub('[A-Z]', 'E',word)\n",
        "    t2 = re.sub('[a-z]', 'e',word)\n",
        "    t3 = re.sub('[ก-๙]', 'T',word)\n",
        "    return re.sub('[0-9]', 'd', t3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upxGZcbP24y1"
      },
      "outputs": [],
      "source": [
        "#Check in Gazetteer\n",
        "def acp_gaz(word):\n",
        "    if word in academic:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def acpfull_gaz(word):\n",
        "    if word in academic_full:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def admin_gaz(word):\n",
        "    if word in admin:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def bsn_gaz(word):\n",
        "    if word in bsn:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def bsnfull_gaz(word):\n",
        "    if word in bsn_full:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def fplace_gaz(word):\n",
        "    if word in fplace:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def gov_gaz(word):\n",
        "    if word in gov:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def govfull_gaz(word):\n",
        "    if word in gov_full:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def hp_gaz(word):\n",
        "    if word in hp:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def hpfull_gaz(word):\n",
        "    if word in hp_full:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def mon_gaz(word):\n",
        "    if word in mon:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def nat_gaz(word):\n",
        "    if word in nat:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def rct_gaz(word):\n",
        "    if word in rct:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def rctfull_gaz(word):\n",
        "    if word in rct_full:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def res_gaz(word):\n",
        "    if word in res:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def resfull_gaz(word):\n",
        "    if word in res_full:\n",
        "        return word\n",
        "    else:\n",
        "        return False \n",
        "\n",
        "def rp_gaz(word):\n",
        "    if word in rp:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def rpfull_gaz(word):\n",
        "    if word in rp_full:\n",
        "        return word\n",
        "    else:\n",
        "        return False \n",
        "\n",
        "def store_gaz(word):\n",
        "    if word in store:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def storefull_gaz(word):\n",
        "    if word in store_full:\n",
        "        return word\n",
        "    else:\n",
        "        return False \n",
        "    \n",
        "def tran_gaz(word):\n",
        "    if word in tran:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def tranfull_gaz(word):\n",
        "    if word in tran_full:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def poiall_gaz(word):\n",
        "    if word in poiall:\n",
        "        return word\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def poifull_gaz(word):\n",
        "    if word in poi_full:\n",
        "        return word\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYkjrb0g24y1"
      },
      "outputs": [],
      "source": [
        "def word_features(sentence,i):\n",
        "    word = sentence[i][0]\n",
        "    pos = sentence[i][1]\n",
        "        \n",
        "    #create feature in current word\n",
        "    features = {\n",
        "                    'bias': 1.0, \n",
        "                    'word': word,\n",
        "                    'word[-3:]' : word[-3:],\n",
        "                    'word[-2:]' : word[-2:],\n",
        "                    'word.is_space()': is_space(word),\n",
        "                    'word.long_word()' : long_word(word),\n",
        "                    'word.shape_word()' : word_shape(word),\n",
        "                    'word.prefix_nat()' : prefix_nat(word),\n",
        "                    'word.prefix_res()' : prefix_res(word),\n",
        "                    'word.prefix_rp()' : prefix_rp(word),\n",
        "                    'word.prefix_acp()' : prefix_acp(word),\n",
        "                    'word.prefix_hp()' : prefix_hp(word),\n",
        "                    'word.prefix_tran()' : prefix_tran(word),\n",
        "                    'word.prefix_store()' : prefix_store(word),\n",
        "                    'word.prefix_mkt()' : prefix_market(word),\n",
        "                    'word.prefix_rt()' : prefix_rt(word),\n",
        "                    'word.prefix_dep()' : prefix_dep(word),\n",
        "                    'word.prefix_bsn()' : prefix_bsn(word),\n",
        "                    'word.prefix_gov()' : prefix_gov(word),\n",
        "                    'word.prefix_rct()' : prefix_rct(word),\n",
        "                    'word.prefix_mon()' : prefix_mon(word),\n",
        "                    'word.prefix_road()' : prefix_road(word),\n",
        "                    'word.prefix_admin()' : prefix_admin(word),\n",
        "                    'word.prep_list()' : prep_list(word),\n",
        "                    'word.acp_gaz()' : acp_gaz(word),\n",
        "                    'word.acpfull_gaz()' : acpfull_gaz(word),\n",
        "                    'word.admin_gaz()' : admin_gaz(word),\n",
        "                    'word.bsn_gaz()' : bsn_gaz(word),\n",
        "                    'word.bsnfull_gaz()' : bsnfull_gaz(word),\n",
        "                    'word.fplace_gaz()' : fplace_gaz(word),\n",
        "                    'word.gov_gaz()' : gov_gaz(word),\n",
        "                    'word.govfull_gaz()' : govfull_gaz(word),\n",
        "                    'word.hp_gaz()' : hp_gaz(word),\n",
        "                    'word.hpfull_gaz()' : hpfull_gaz(word),\n",
        "                    'word.mon_gaz()' : mon_gaz(word),\n",
        "                    'word.nat_gaz()' : nat_gaz(word),\n",
        "                    'word.rct_gaz()' : rct_gaz(word),\n",
        "                    'word.rctfull_gaz()' : rctfull_gaz(word),\n",
        "                    'word.res_gaz()' : res_gaz(word),\n",
        "                    'word.resfull_gaz()' : resfull_gaz(word),\n",
        "                    'word.rp_gaz()' : rp_gaz(word),\n",
        "                    'word.rpfull_gaz()' : rpfull_gaz(word),\n",
        "                    'word.store_gaz()' : store_gaz(word),\n",
        "                    'word.storefull_gaz()' : storefull_gaz(word),\n",
        "                    'word.tran_gaz()' : tran_gaz(word),\n",
        "                    'word.tranfull_gaz()' : tranfull_gaz(word),\n",
        "                    'word.poiall_gaz()' : poiall_gaz(word),\n",
        "                    'word.poifull_gaz()' : poifull_gaz(word),\n",
        "                    'postag': pos\n",
        "                }\n",
        "        #If this is not the first word of sentence \n",
        "    if i > 0:\n",
        "        prev_word = sentence[i-1][0]\n",
        "        prev_pos = sentence[i-1][1]\n",
        "        features.update({\n",
        "                            '-1:word' : prev_word,\n",
        "                            '-1:word.is_space' : is_space(prev_word),\n",
        "                            '-1:word.long_word()' : long_word(prev_word),\n",
        "                            '-1:word.shape_word()' : word_shape(prev_word),\n",
        "                            '-1:word.prefix_nat()' : prefix_nat(prev_word),\n",
        "                            '-1:word.prefix_res()' : prefix_res(prev_word),\n",
        "                            '-1:word.prefix_rp()' : prefix_rp(prev_word),\n",
        "                            '-1:word.prefix_acp()' : prefix_acp(prev_word),\n",
        "                            '-1:word.prefix_hp()' : prefix_hp(prev_word),\n",
        "                            '-1:word.prefix_tran()' : prefix_tran(prev_word),\n",
        "                            '-1:word.prefix_store()' : prefix_store(prev_word),\n",
        "                            '-1:word.prefix_mkt()' : prefix_market(prev_word),\n",
        "                            '-1:word.prefix_rt()' : prefix_rt(prev_word),\n",
        "                            '-1:word.prefix_dep()' : prefix_dep(prev_word),\n",
        "                            '-1:word.prefix_bsn()' : prefix_bsn(prev_word),\n",
        "                            '-1:word.prefix_gov()' : prefix_gov(prev_word),\n",
        "                            '-1:word.prefix_rct()' : prefix_rct(prev_word),\n",
        "                            '-1:word.prefix_mon()' : prefix_mon(prev_word),\n",
        "                            '-1:word.prefix_road()' : prefix_road(prev_word),\n",
        "                            '-1:word.prefix_admin()' : prefix_admin(prev_word),\n",
        "                            '-1:word.prep_list()' : prep_list(prev_word),\n",
        "                            '-1:word.acp_gaz()' : acp_gaz(prev_word),\n",
        "                            '-1:word.acpfull_gaz()' : acpfull_gaz(prev_word),\n",
        "                            '-1:word.admin_gaz()' : admin_gaz(prev_word),\n",
        "                            '-1:word.bsn_gaz()' : bsn_gaz(prev_word),\n",
        "                            '-1:word.bsnfull_gaz()' : bsnfull_gaz(prev_word),\n",
        "                            '-1:word.fplace_gaz()' : fplace_gaz(prev_word),\n",
        "                            '-1:word.gov_gaz()' : gov_gaz(prev_word),\n",
        "                            '-1:word.govfull_gaz()' : govfull_gaz(prev_word),\n",
        "                            '-1:word.hp_gaz()' : hp_gaz(prev_word),\n",
        "                            '-1:word.hpfull_gaz()' : hpfull_gaz(prev_word),\n",
        "                            '-1:word.mon_gaz()' : mon_gaz(prev_word),\n",
        "                            '-1:word.nat_gaz()' : nat_gaz(prev_word),\n",
        "                            '-1:word.rct_gaz()' : rct_gaz(prev_word),\n",
        "                            '-1:word.rctfull_gaz()' : rctfull_gaz(prev_word),\n",
        "                            '-1:word.res_gaz()' : res_gaz(prev_word),\n",
        "                            '-1:word.resfull_gaz()' : resfull_gaz(prev_word),\n",
        "                            '-1:word.rp_gaz()' : rp_gaz(prev_word),\n",
        "                            '-1:word.rpfull_gaz()' : rpfull_gaz(prev_word),\n",
        "                            '-1:word.store_gaz()' : store_gaz(prev_word),\n",
        "                            '-1:word.storefull_gaz()' : storefull_gaz(prev_word),\n",
        "                            '-1:word.tran_gaz()' : tran_gaz(prev_word),\n",
        "                            '-1:word.tranfull_gaz()' : tranfull_gaz(prev_word),\n",
        "                            '-1:word.poiall_gaz()' : poiall_gaz(prev_word),\n",
        "                            '-1:word.poifull_gaz()' : poifull_gaz(prev_word),\n",
        "                            '-1:postag' : prev_pos\n",
        "                        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "        \n",
        "    if i < len(sentence)-1:\n",
        "        next_word = sentence[i+1][0]\n",
        "        next_pos = sentence[i+1][0]\n",
        "        features.update({\n",
        "                            '+1:word' : next_word,\n",
        "                            '+1:word.is_space' : is_space(next_word),\n",
        "                            '+1:word.long_word()' : long_word(next_word),\n",
        "                            '+1:word.suffix_res()' : suffix_res(next_word),\n",
        "                            '+1:word.suffix_rp()' : suffix_rp(next_word),\n",
        "                            '+1:word.suffix_acp()' : suffix_acp(next_word),\n",
        "                            '+1:word.suffix_store()' : suffix_store(next_word),\n",
        "                            '+1:word.suffix_rt()' : suffix_rt(next_word),\n",
        "                            '+1:word.suffix_dep()' : suffix_dep(next_word),\n",
        "                            '+1:word.acp_gaz()' : acp_gaz(next_word),\n",
        "                            '+1:word.acpfull_gaz()' : acpfull_gaz(next_word),\n",
        "                            '+1:word.admin_gaz()' : admin_gaz(next_word),\n",
        "                            '+1:word.bsn_gaz()' : bsn_gaz(next_word),\n",
        "                            '+1:word.bsnfull_gaz()' : bsnfull_gaz(next_word),\n",
        "                            '+1:word.fplace_gaz()' : fplace_gaz(next_word),\n",
        "                            '+1:word.gov_gaz()' : gov_gaz(next_word),\n",
        "                            '+1:word.govfull_gaz()' : govfull_gaz(next_word),\n",
        "                            '+1:word.hp_gaz()' : hp_gaz(next_word),\n",
        "                            '+1:word.hpfull_gaz()' : hpfull_gaz(next_word),\n",
        "                            '+1:word.mon_gaz()' : mon_gaz(next_word),\n",
        "                            '+1:word.nat_gaz()' : nat_gaz(next_word),\n",
        "                            '+1:word.rct_gaz()' : rct_gaz(next_word),\n",
        "                            '+1:word.rctfull_gaz()' : rctfull_gaz(next_word),\n",
        "                            '+1:word.res_gaz()' : res_gaz(next_word),\n",
        "                            '+1:word.resfull_gaz()' : resfull_gaz(next_word),\n",
        "                            '+1:word.rp_gaz()' : rp_gaz(next_word),\n",
        "                            '+1:word.rpfull_gaz()' : rpfull_gaz(next_word),\n",
        "                            '+1:word.store_gaz()' : store_gaz(next_word),\n",
        "                            '+1:word.storefull_gaz()' : storefull_gaz(next_word),\n",
        "                            '+1:word.tran_gaz()' : tran_gaz(next_word),\n",
        "                            '+1:word.tranfull_gaz()' : tranfull_gaz(next_word),\n",
        "                            '+1word.poiall_gaz()' : poiall_gaz(next_word),\n",
        "                            '+1:word.poifull_gaz()' : poifull_gaz(next_word),\n",
        "                            '+1:postag' : next_pos\n",
        "                        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "        \n",
        "    if i > 1:\n",
        "        prev_word2 = sentence[i-2][0]\n",
        "        prev_pos2 = sentence[i-2][1]\n",
        "        features.update({\n",
        "                           \n",
        "                            '-2:word' : prev_word2,\n",
        "                            '-2:word.is_space' : is_space(prev_word2),\n",
        "                            '-2:word.long_word()' : long_word(prev_word2),\n",
        "                            '-2:word.shape_word()' : word_shape(prev_word2),\n",
        "                            '-2:word.prefix_nat()' : prefix_nat(prev_word2),\n",
        "                            '-2:word.prefix_res()' : prefix_res(prev_word2),\n",
        "                            '-2:word.prefix_rp()' : prefix_rp(prev_word2),\n",
        "                            '-2:word.prefix_acp()' : prefix_acp(prev_word2),\n",
        "                            '-2:word.prefix_hp()' : prefix_hp(prev_word2),\n",
        "                            '-2:word.prefix_tran()' : prefix_tran(prev_word2),\n",
        "                            '-2:word.prefix_store()' : prefix_store(prev_word2),\n",
        "                            '-2:word.prefix_mkt()' : prefix_market(prev_word2),\n",
        "                            '-2:word.prefix_rt()' : prefix_rt(prev_word2),\n",
        "                            '-2:word.prefix_dep()' : prefix_dep(prev_word2),\n",
        "                            '-2:word.prefix_bsn()' : prefix_bsn(prev_word2),\n",
        "                            '-2:word.prefix_gov()' : prefix_gov(prev_word2),\n",
        "                            '-2:word.prefix_rct()' : prefix_rct(prev_word2),\n",
        "                            '-2:word.prefix_mon()' : prefix_mon(prev_word2),\n",
        "                            '-2:word.prefix_road()' : prefix_road(prev_word2),\n",
        "                            '-2:word.prefix_admin()' : prefix_admin(prev_word2),\n",
        "                            '-2:word.prep_list()' : prep_list(prev_word2),\n",
        "                            '-2:word.acp_gaz()' : acp_gaz(prev_word2),\n",
        "                            '-2:word.acpfull_gaz()' : acpfull_gaz(prev_word2),\n",
        "                            '-2:word.admin_gaz()' : admin_gaz(prev_word2),\n",
        "                            '-2:word.bsn_gaz()' : bsn_gaz(prev_word2),\n",
        "                            '-2:word.bsnfull_gaz()' : bsnfull_gaz(prev_word2),\n",
        "                            '-2:word.fplace_gaz()' : fplace_gaz(prev_word2),\n",
        "                            '-2:word.gov_gaz()' : gov_gaz(prev_word2),\n",
        "                            '-2:word.govfull_gaz()' : govfull_gaz(prev_word2),\n",
        "                            '-2:word.hp_gaz()' : hp_gaz(prev_word2),\n",
        "                            '-2:word.hpfull_gaz()' : hpfull_gaz(prev_word2),\n",
        "                            '-2:word.mon_gaz()' : mon_gaz(prev_word2),\n",
        "                            '-2:word.nat_gaz()' : nat_gaz(prev_word2),\n",
        "                            '-2:word.rct_gaz()' : rct_gaz(prev_word2),\n",
        "                            '-2:word.rctfull_gaz()' : rctfull_gaz(prev_word2),\n",
        "                            '-2:word.res_gaz()' : res_gaz(prev_word2),\n",
        "                            '-2:word.resfull_gaz()' : resfull_gaz(prev_word2),\n",
        "                            '-2:word.rp_gaz()' : rp_gaz(prev_word2),\n",
        "                            '-2:word.rpfull_gaz()' : rpfull_gaz(prev_word2),\n",
        "                            '-2:word.store_gaz()' : store_gaz(prev_word2),\n",
        "                            '-2:word.storefull_gaz()' : storefull_gaz(prev_word2),\n",
        "                            '-2:word.tran_gaz()' : tran_gaz(prev_word2),\n",
        "                            '-2:word.tranfull_gaz()' : tranfull_gaz(prev_word2),\n",
        "                            '-2:word.poiall_gaz()' : poiall_gaz(prev_word2),\n",
        "                            '-2:word.poifull_gaz()' : poifull_gaz(prev_word2),\n",
        "                            '-2:postag' : prev_pos2\n",
        "                        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "   \n",
        "    if i < len(sentence)-2:\n",
        "        next_word2 = sentence[i+2][0]\n",
        "        next_pos2 = sentence[i+2][0]\n",
        "        features.update({\n",
        "                           \n",
        "                            '+2:word' : next_word2,\n",
        "                            '+2:word.is_space' : is_space(next_word2),\n",
        "                            '+2:word.long_word()' : long_word(next_word2),\n",
        "                            '+2:word.shape_word()' : word_shape(next_word2),\n",
        "                            '+2:word.suffix_res()' : suffix_res(next_word2),\n",
        "                            '+2:word.suffix_rp()' : suffix_rp(next_word2),\n",
        "                            '+2:word.suffix_acp()' : suffix_acp(next_word2),\n",
        "                            '+2:word.suffix_store()' : suffix_store(next_word2),\n",
        "                            '+2:word.suffix_rt()' : suffix_rt(next_word2),\n",
        "                            '+2:word.suffix_dep()' : suffix_dep(next_word2),\n",
        "                            '+2:word.acp_gaz()' : acp_gaz(next_word2),\n",
        "                            '+2:word.acpfull_gaz()' : acpfull_gaz(next_word2),\n",
        "                            '+2:word.admin_gaz()' : admin_gaz(next_word2),\n",
        "                            '+2:word.bsn_gaz()' : bsn_gaz(next_word2),\n",
        "                            '+2:word.bsnfull_gaz()' : bsnfull_gaz(next_word2),\n",
        "                            '+2:word.fplace_gaz()' : fplace_gaz(next_word2),\n",
        "                            '+2:word.gov_gaz()' : gov_gaz(next_word2),\n",
        "                            '+2:word.govfull_gaz()' : govfull_gaz(next_word2),\n",
        "                            '+2:word.hp_gaz()' : hp_gaz(next_word2),\n",
        "                            '+2:word.hpfull_gaz()' : hpfull_gaz(next_word2),\n",
        "                            '+2:word.mon_gaz()' : mon_gaz(next_word2),\n",
        "                            '+2:word.nat_gaz()' : nat_gaz(next_word2),\n",
        "                            '+2:word.rct_gaz()' : rct_gaz(next_word2),\n",
        "                            '+2:word.rctfull_gaz()' : rctfull_gaz(next_word2),\n",
        "                            '+2:word.res_gaz()' : res_gaz(next_word2),\n",
        "                            '+2:word.resfull_gaz()' : resfull_gaz(next_word2),\n",
        "                            '+2:word.rp_gaz()' : rp_gaz(next_word2),\n",
        "                            '+2:word.rpfull_gaz()' : rpfull_gaz(next_word2),\n",
        "                            '+2:word.store_gaz()' : store_gaz(next_word2),\n",
        "                            '+2:word.storefull_gaz()' : storefull_gaz(next_word2),\n",
        "                            '+2:word.tran_gaz()' : tran_gaz(next_word2),\n",
        "                            '+2:word.tranfull_gaz()' : tranfull_gaz(next_word2),\n",
        "                            '+2:word.poiall_gaz()' : poiall_gaz(next_word2),\n",
        "                            '+2:word.poifull_gaz()' : poifull_gaz(next_word2),\n",
        "                            '+2:postag' : next_pos2\n",
        "                        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "        \n",
        "    if i > 2:\n",
        "        prev_word3 = sentence[i-3][0]\n",
        "        prev_pos3 = sentence[i-3][1]\n",
        "        features.update({\n",
        "                            '-3:word' : prev_word3,\n",
        "                            '-3:word.is_space' : is_space(prev_word3),\n",
        "                            '-3:word.long_word()' : long_word(prev_word3),\n",
        "                            '-3:word.shape_word()' : word_shape(prev_word3),\n",
        "                            '-3:word.prefix_nat()' : prefix_nat(prev_word3),\n",
        "                            '-3:word.prefix_res()' : prefix_res(prev_word3),\n",
        "                            '-3:word.prefix_rp()' : prefix_rp(prev_word3),\n",
        "                            '-3:word.prefix_acp()' : prefix_acp(prev_word3),\n",
        "                            '-3:word.prefix_hp()' : prefix_hp(prev_word3),\n",
        "                            '-3:word.prefix_tran()' : prefix_tran(prev_word3),\n",
        "                            '-3:word.prefix_store()' : prefix_store(prev_word3),\n",
        "                            '-3:word.prefix_mkt()' : prefix_market(prev_word3),\n",
        "                            '-3:word.prefix_rt()' : prefix_rt(prev_word3),\n",
        "                            '-3:word.prefix_dep()' : prefix_dep(prev_word3),\n",
        "                            '-3:word.prefix_bsn()' : prefix_bsn(prev_word3),\n",
        "                            '-3:word.prefix_gov()' : prefix_gov(prev_word3),\n",
        "                            '-3:word.prefix_rct()' : prefix_rct(prev_word3),\n",
        "                            '-3:word.prefix_mon()' : prefix_mon(prev_word3),\n",
        "                            '-3:word.prefix_road()' : prefix_road(prev_word3),\n",
        "                            '-3:word.prefix_admin()' : prefix_admin(prev_word3),\n",
        "                            '-3:word.prep_list()' : prep_list(prev_word3),\n",
        "                            '-3:word.acp_gaz()' : acp_gaz(prev_word3),\n",
        "                            '-3:word.acpfull_gaz()' : acpfull_gaz(prev_word3),\n",
        "                            '-3:word.admin_gaz()' : admin_gaz(prev_word3),\n",
        "                            '-3:word.bsn_gaz()' : bsn_gaz(prev_word3),\n",
        "                            '-3:word.bsnfull_gaz()' : bsnfull_gaz(prev_word3),\n",
        "                            '-3:word.fplace_gaz()' : fplace_gaz(prev_word3),\n",
        "                            '-3:word.gov_gaz()' : gov_gaz(prev_word3),\n",
        "                            '-3:word.govfull_gaz()' : govfull_gaz(prev_word3),\n",
        "                            '-3:word.hp_gaz()' : hp_gaz(prev_word3),\n",
        "                            '-3:word.hpfull_gaz()' : hpfull_gaz(prev_word3),\n",
        "                            '-3:word.mon_gaz()' : mon_gaz(prev_word3),\n",
        "                            '-3:word.nat_gaz()' : nat_gaz(prev_word3),\n",
        "                            '-3:word.rct_gaz()' : rct_gaz(prev_word3),\n",
        "                            '-3:word.rctfull_gaz()' : rctfull_gaz(prev_word3),\n",
        "                            '-3:word.res_gaz()' : res_gaz(prev_word3),\n",
        "                            '-3:word.resfull_gaz()' : resfull_gaz(prev_word3),\n",
        "                            '-3:word.rp_gaz()' : rp_gaz(prev_word3),\n",
        "                            '-3:word.rpfull_gaz()' : rpfull_gaz(prev_word3),\n",
        "                            '-3:word.store_gaz()' : store_gaz(prev_word3),\n",
        "                            '-3:word.storefull_gaz()' : storefull_gaz(prev_word3),\n",
        "                            '-3:word.tran_gaz()' : tran_gaz(prev_word3),\n",
        "                            '-3:word.tranfull_gaz()' : tranfull_gaz(prev_word3),\n",
        "                            '-3:word.poiall_gaz()' : poiall_gaz(prev_word3),\n",
        "                            '-3:word.poifull_gaz()' : poifull_gaz(prev_word3),\n",
        "                            '-3:postag' : prev_pos3\n",
        "                        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "        \n",
        "    \n",
        "    if i < len(sentence)-3:\n",
        "        next_word3 = sentence[i+3][0]\n",
        "        next_pos3 = sentence[i+3][0]\n",
        "        features.update({\n",
        "                            '+3:word' : next_word3,\n",
        "                            '+3:word.is_space' : is_space(next_word3),\n",
        "                            '+3:word.long_word()' : long_word(next_word3),\n",
        "                            '+3:word.shape_word()' : word_shape(next_word3),\n",
        "                            '+3:word.suffix_res()' : suffix_res(next_word3),\n",
        "                            '+3:word.suffix_rp()' : suffix_rp(next_word3),\n",
        "                            '+3:word.suffix_acp()' : suffix_acp(next_word3),\n",
        "                            '+3:word.suffix_store()' : suffix_store(next_word3),\n",
        "                            '+3:word.suffix_rt()' : suffix_rt(next_word3),\n",
        "                            '+3:word.suffix_dep()' : suffix_dep(next_word3),\n",
        "                            '+3:word.acp_gaz()' : acp_gaz(next_word3),\n",
        "                            '+3:word.acpfull_gaz()' : acpfull_gaz(next_word3),\n",
        "                            '+3:word.admin_gaz()' : admin_gaz(next_word3),\n",
        "                            '+3:word.bsn_gaz()' : bsn_gaz(next_word3),\n",
        "                            '+3:word.bsnfull_gaz()' : bsnfull_gaz(next_word3),\n",
        "                            '+3:word.fplace_gaz()' : fplace_gaz(next_word3),\n",
        "                            '+3:word.gov_gaz()' : gov_gaz(next_word3),\n",
        "                            '+3:word.govfull_gaz()' : govfull_gaz(next_word3),\n",
        "                            '+3:word.hp_gaz()' : hp_gaz(next_word3),\n",
        "                            '+3:word.hpfull_gaz()' : hpfull_gaz(next_word3),\n",
        "                            '+3:word.mon_gaz()' : mon_gaz(next_word3),\n",
        "                            '+3:word.nat_gaz()' : nat_gaz(next_word3),\n",
        "                            '+3:word.rct_gaz()' : rct_gaz(next_word3),\n",
        "                            '+3:word.rctfull_gaz()' : rctfull_gaz(next_word3),\n",
        "                            '+3:word.res_gaz()' : res_gaz(next_word3),\n",
        "                            '+3:word.resfull_gaz()' : resfull_gaz(next_word3),\n",
        "                            '+3:word.rp_gaz()' : rp_gaz(next_word3),\n",
        "                            '+3:word.rpfull_gaz()' : rpfull_gaz(next_word3),\n",
        "                            '+3:word.store_gaz()' : store_gaz(next_word3),\n",
        "                            '+3:word.storefull_gaz()' : storefull_gaz(next_word3),\n",
        "                            '+3:word.tran_gaz()' : tran_gaz(next_word3),\n",
        "                            '+3:word.tranfull_gaz()' : tranfull_gaz(next_word3),\n",
        "                            '+3:word.poiall_gaz()' : poiall_gaz(next_word3),\n",
        "                            '+3:word.poifull_gaz()' : poifull_gaz(next_word3),\n",
        "                            '+3:postag' : next_pos3\n",
        "                        })\n",
        "    else:\n",
        "        features['EOS'] = True  \n",
        "        \n",
        "    return features\n",
        "                \n",
        "#return feature dictionary for each word\n",
        "def sentence_features(sentence):\n",
        "    return [word_features(sentence,i) for i in range(len(sentence))]\n",
        "\n",
        "#return the label NER tags\n",
        "def sentence_labels(sentence):\n",
        "    return [label for token,pos,label in sentence]\n",
        "\n",
        "#return token \n",
        "def sentence_tokens(sentence):\n",
        "    return [token for token,pos,label in sentence]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwRt2Ztp24y3",
        "outputId": "ea47e975-0bc5-4a6b-a09b-54a11d7f5108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17955/17955 [00:54<00:00, 326.73it/s]\n",
            "100%|██████████| 5617/5617 [00:21<00:00, 263.21it/s]\n",
            "100%|██████████| 17955/17955 [00:00<00:00, 335940.23it/s]\n",
            "100%|██████████| 5617/5617 [00:00<00:00, 321358.11it/s]\n",
            "100%|██████████| 17955/17955 [00:00<00:00, 333799.01it/s]\n",
            "100%|██████████| 5617/5617 [00:00<00:00, 136505.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 6s, sys: 11.8 s, total: 1min 17s\n",
            "Wall time: 1min 18s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#Prepare word for train test\n",
        "X = [sentence_features(sentence) for sentence in tqdm(train_data)]\n",
        "X_test = [sentence_features(sentence) for sentence in tqdm(test_data)]\n",
        "\n",
        "#Label train test\n",
        "y = [sentence_labels(sentence) for sentence in tqdm(train_data)]\n",
        "y_test = [sentence_labels(sentence) for sentence in tqdm(test_data)]\n",
        "\n",
        "#Get token \n",
        "Train_token = [sentence_tokens(sentence) for sentence in tqdm(train_data)]\n",
        "Test_tokens = [sentence_tokens(sentence) for sentence in tqdm(test_data)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4_pNCgw24y3",
        "outputId": "e821a3fa-c386-4cc9-f556-0d13f2de26dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading training data to CRFsuite: 100%|██████████| 17955/17955 [02:01<00:00, 148.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 1\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 647667\n",
            "Seconds required: 17.119\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.100000\n",
            "c2: 0.100000\n",
            "num_memories: 6\n",
            "max_iterations: 200\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=35.68 loss=138269.68 active=634788 feature_norm=1.00\n",
            "Iter 2   time=17.75 loss=137603.25 active=615470 feature_norm=0.99\n",
            "Iter 3   time=17.84 loss=125364.29 active=260154 feature_norm=1.08\n",
            "Iter 4   time=18.57 loss=116009.06 active=352604 feature_norm=1.14\n",
            "Iter 5   time=19.06 loss=108854.98 active=365861 feature_norm=1.35\n",
            "Iter 6   time=18.02 loss=89632.08 active=325423 feature_norm=2.40\n",
            "Iter 7   time=35.70 loss=81337.15 active=333722 feature_norm=2.66\n",
            "Iter 8   time=17.90 loss=78257.80 active=355252 feature_norm=3.41\n",
            "Iter 9   time=35.90 loss=73414.92 active=354466 feature_norm=3.47\n",
            "Iter 10  time=18.23 loss=70749.24 active=368917 feature_norm=3.89\n",
            "Iter 11  time=18.01 loss=69751.60 active=364064 feature_norm=4.06\n",
            "Iter 12  time=17.72 loss=66264.38 active=388724 feature_norm=4.23\n",
            "Iter 13  time=17.69 loss=65333.81 active=385326 feature_norm=4.34\n",
            "Iter 14  time=17.66 loss=64098.35 active=390703 feature_norm=4.49\n",
            "Iter 15  time=17.64 loss=62999.86 active=386351 feature_norm=4.63\n",
            "Iter 16  time=35.26 loss=60635.18 active=367680 feature_norm=4.77\n",
            "Iter 17  time=18.04 loss=59302.20 active=374538 feature_norm=5.04\n",
            "Iter 18  time=35.08 loss=58529.88 active=367818 feature_norm=5.10\n",
            "Iter 19  time=17.61 loss=57778.86 active=363854 feature_norm=5.36\n",
            "Iter 20  time=17.56 loss=57128.38 active=359166 feature_norm=5.63\n",
            "Iter 21  time=17.67 loss=55624.08 active=361087 feature_norm=5.92\n",
            "Iter 22  time=17.70 loss=54230.72 active=352581 feature_norm=6.31\n",
            "Iter 23  time=17.75 loss=50141.04 active=340595 feature_norm=8.59\n",
            "Iter 24  time=17.66 loss=47991.60 active=333780 feature_norm=10.90\n",
            "Iter 25  time=17.72 loss=44441.66 active=331493 feature_norm=12.54\n",
            "Iter 26  time=17.59 loss=42983.56 active=342744 feature_norm=13.48\n",
            "Iter 27  time=17.49 loss=41296.85 active=339299 feature_norm=14.85\n",
            "Iter 28  time=35.54 loss=39044.60 active=330601 feature_norm=21.10\n",
            "Iter 29  time=17.86 loss=33766.18 active=340377 feature_norm=26.81\n",
            "Iter 30  time=17.75 loss=32249.47 active=338078 feature_norm=28.59\n",
            "Iter 31  time=17.74 loss=30541.62 active=338763 feature_norm=27.86\n",
            "Iter 32  time=17.77 loss=29363.47 active=335570 feature_norm=29.85\n",
            "Iter 33  time=17.66 loss=27649.65 active=331389 feature_norm=33.51\n",
            "Iter 34  time=19.77 loss=26208.28 active=325540 feature_norm=38.88\n",
            "Iter 35  time=18.02 loss=24205.86 active=327639 feature_norm=42.04\n",
            "Iter 36  time=17.77 loss=22834.10 active=323941 feature_norm=43.82\n",
            "Iter 37  time=17.80 loss=21552.65 active=322800 feature_norm=45.54\n",
            "Iter 38  time=35.19 loss=20562.40 active=318542 feature_norm=47.44\n",
            "Iter 39  time=17.52 loss=19415.39 active=318887 feature_norm=48.85\n",
            "Iter 40  time=17.54 loss=17146.13 active=312621 feature_norm=53.03\n",
            "Iter 41  time=17.62 loss=15972.92 active=302321 feature_norm=59.45\n",
            "Iter 42  time=17.54 loss=13837.70 active=301981 feature_norm=62.95\n",
            "Iter 43  time=17.57 loss=12939.52 active=301519 feature_norm=64.20\n",
            "Iter 44  time=17.74 loss=11929.74 active=298185 feature_norm=67.43\n",
            "Iter 45  time=17.71 loss=11054.33 active=294333 feature_norm=71.53\n",
            "Iter 46  time=17.75 loss=10229.76 active=292817 feature_norm=73.90\n",
            "Iter 47  time=17.75 loss=9400.78  active=285821 feature_norm=78.30\n",
            "Iter 48  time=17.67 loss=8575.59  active=275349 feature_norm=82.31\n",
            "Iter 49  time=17.71 loss=7991.83  active=266528 feature_norm=86.61\n",
            "Iter 50  time=17.69 loss=7559.37  active=259250 feature_norm=88.64\n",
            "Iter 51  time=17.74 loss=7077.07  active=255655 feature_norm=91.91\n",
            "Iter 52  time=17.53 loss=6783.99  active=251002 feature_norm=93.33\n",
            "Iter 53  time=17.53 loss=6548.69  active=251357 feature_norm=95.12\n",
            "Iter 54  time=17.61 loss=6385.45  active=250090 feature_norm=96.09\n",
            "Iter 55  time=18.04 loss=6159.06  active=242691 feature_norm=99.86\n",
            "Iter 56  time=17.61 loss=6060.41  active=241881 feature_norm=100.12\n",
            "Iter 57  time=17.48 loss=5976.84  active=243674 feature_norm=100.00\n",
            "Iter 58  time=17.50 loss=5950.11  active=243350 feature_norm=99.95\n",
            "Iter 59  time=17.57 loss=5876.39  active=240106 feature_norm=100.31\n",
            "Iter 60  time=17.62 loss=5821.40  active=235601 feature_norm=101.15\n",
            "Iter 61  time=17.46 loss=5734.62  active=234628 feature_norm=101.37\n",
            "Iter 62  time=17.55 loss=5686.67  active=231566 feature_norm=101.93\n",
            "Iter 63  time=17.48 loss=5609.36  active=221928 feature_norm=103.47\n",
            "Iter 64  time=17.50 loss=5547.99  active=217723 feature_norm=103.88\n",
            "Iter 65  time=17.48 loss=5493.04  active=213240 feature_norm=104.58\n",
            "Iter 66  time=17.44 loss=5435.82  active=209070 feature_norm=104.97\n",
            "Iter 67  time=17.48 loss=5392.41  active=205662 feature_norm=105.21\n",
            "Iter 68  time=17.70 loss=5347.35  active=203023 feature_norm=105.12\n",
            "Iter 69  time=18.21 loss=5299.97  active=200290 feature_norm=105.33\n",
            "Iter 70  time=17.68 loss=5256.56  active=197977 feature_norm=105.15\n",
            "Iter 71  time=17.58 loss=5217.71  active=196102 feature_norm=105.36\n",
            "Iter 72  time=17.65 loss=5179.46  active=193809 feature_norm=105.20\n",
            "Iter 73  time=17.66 loss=5144.74  active=191848 feature_norm=105.38\n",
            "Iter 74  time=17.49 loss=5111.69  active=189704 feature_norm=105.20\n",
            "Iter 75  time=17.50 loss=5081.15  active=188836 feature_norm=105.35\n",
            "Iter 76  time=17.47 loss=5051.23  active=186945 feature_norm=105.17\n",
            "Iter 77  time=17.46 loss=5025.32  active=185644 feature_norm=105.32\n",
            "Iter 78  time=17.61 loss=5002.54  active=183376 feature_norm=105.12\n",
            "Iter 79  time=17.50 loss=4982.29  active=182230 feature_norm=105.17\n",
            "Iter 80  time=17.45 loss=4961.67  active=180496 feature_norm=104.96\n",
            "Iter 81  time=17.45 loss=4941.85  active=179008 feature_norm=104.95\n",
            "Iter 82  time=17.49 loss=4924.04  active=176950 feature_norm=104.69\n",
            "Iter 83  time=17.73 loss=4908.07  active=175803 feature_norm=104.68\n",
            "Iter 84  time=17.51 loss=4892.97  active=174075 feature_norm=104.44\n",
            "Iter 85  time=17.45 loss=4878.71  active=173209 feature_norm=104.42\n",
            "Iter 86  time=17.51 loss=4865.21  active=171633 feature_norm=104.17\n",
            "Iter 87  time=17.55 loss=4853.34  active=171177 feature_norm=104.16\n",
            "Iter 88  time=17.44 loss=4842.24  active=169817 feature_norm=103.93\n",
            "Iter 89  time=17.50 loss=4831.56  active=168899 feature_norm=103.93\n",
            "Iter 90  time=17.48 loss=4820.96  active=167386 feature_norm=103.77\n",
            "Iter 91  time=17.51 loss=4811.37  active=167182 feature_norm=103.78\n",
            "Iter 92  time=17.61 loss=4802.44  active=166243 feature_norm=103.66\n",
            "Iter 93  time=17.50 loss=4794.32  active=165893 feature_norm=103.68\n",
            "Iter 94  time=17.48 loss=4785.77  active=164896 feature_norm=103.59\n",
            "Iter 95  time=17.46 loss=4777.81  active=164156 feature_norm=103.60\n",
            "Iter 96  time=17.58 loss=4770.22  active=163104 feature_norm=103.47\n",
            "Iter 97  time=17.62 loss=4763.17  active=163034 feature_norm=103.53\n",
            "Iter 98  time=17.50 loss=4756.55  active=162305 feature_norm=103.42\n",
            "Iter 99  time=17.55 loss=4750.63  active=162023 feature_norm=103.47\n",
            "Iter 100 time=17.49 loss=4744.55  active=161065 feature_norm=103.36\n",
            "Iter 101 time=17.54 loss=4739.08  active=160831 feature_norm=103.43\n",
            "Iter 102 time=17.48 loss=4733.83  active=160032 feature_norm=103.28\n",
            "Iter 103 time=17.55 loss=4728.86  active=159943 feature_norm=103.38\n",
            "Iter 104 time=17.54 loss=4723.73  active=159321 feature_norm=103.27\n",
            "Iter 105 time=17.46 loss=4719.66  active=158827 feature_norm=103.33\n",
            "Iter 106 time=17.55 loss=4715.25  active=158002 feature_norm=103.22\n",
            "Iter 107 time=17.54 loss=4712.36  active=157788 feature_norm=103.32\n",
            "Iter 108 time=17.53 loss=4707.67  active=157380 feature_norm=103.20\n",
            "Iter 109 time=17.48 loss=4704.59  active=157405 feature_norm=103.29\n",
            "Iter 110 time=17.55 loss=4700.56  active=156903 feature_norm=103.23\n",
            "Iter 111 time=17.88 loss=4697.66  active=156493 feature_norm=103.28\n",
            "Iter 112 time=17.48 loss=4694.36  active=155822 feature_norm=103.23\n",
            "Iter 113 time=17.53 loss=4692.03  active=155615 feature_norm=103.30\n",
            "Iter 114 time=17.45 loss=4688.24  active=155282 feature_norm=103.25\n",
            "Iter 115 time=17.51 loss=4686.22  active=155105 feature_norm=103.34\n",
            "Iter 116 time=17.39 loss=4682.68  active=154702 feature_norm=103.29\n",
            "Iter 117 time=17.54 loss=4680.61  active=154533 feature_norm=103.36\n",
            "Iter 118 time=17.41 loss=4677.68  active=154143 feature_norm=103.34\n",
            "Iter 119 time=17.45 loss=4675.66  active=154010 feature_norm=103.39\n",
            "Iter 120 time=17.45 loss=4673.05  active=153541 feature_norm=103.35\n",
            "Iter 121 time=17.32 loss=4671.66  active=153576 feature_norm=103.41\n",
            "Iter 122 time=17.47 loss=4668.74  active=153263 feature_norm=103.38\n",
            "Iter 123 time=17.44 loss=4667.31  active=153419 feature_norm=103.43\n",
            "Iter 124 time=17.51 loss=4664.58  active=153167 feature_norm=103.42\n",
            "Iter 125 time=17.40 loss=4663.27  active=153022 feature_norm=103.45\n",
            "Iter 126 time=17.38 loss=4660.87  active=152861 feature_norm=103.44\n",
            "Iter 127 time=17.44 loss=4659.64  active=152833 feature_norm=103.48\n",
            "Iter 128 time=17.37 loss=4657.26  active=152514 feature_norm=103.47\n",
            "Iter 129 time=17.42 loss=4656.31  active=152399 feature_norm=103.51\n",
            "Iter 130 time=17.37 loss=4653.86  active=152185 feature_norm=103.49\n",
            "Iter 131 time=17.47 loss=4652.82  active=152230 feature_norm=103.53\n",
            "Iter 132 time=17.37 loss=4650.62  active=151932 feature_norm=103.52\n",
            "Iter 133 time=17.36 loss=4649.39  active=151858 feature_norm=103.55\n",
            "Iter 134 time=17.45 loss=4647.34  active=151529 feature_norm=103.53\n",
            "Iter 135 time=17.62 loss=4645.91  active=151512 feature_norm=103.56\n",
            "Iter 136 time=17.62 loss=4644.09  active=151414 feature_norm=103.54\n",
            "Iter 137 time=17.55 loss=4643.07  active=151422 feature_norm=103.57\n",
            "Iter 138 time=17.66 loss=4640.88  active=151271 feature_norm=103.55\n",
            "Iter 139 time=17.77 loss=4639.74  active=151577 feature_norm=103.58\n",
            "Iter 140 time=17.53 loss=4637.75  active=151440 feature_norm=103.57\n",
            "Iter 141 time=17.57 loss=4636.57  active=151458 feature_norm=103.59\n",
            "Iter 142 time=17.52 loss=4634.94  active=151093 feature_norm=103.57\n",
            "Iter 143 time=17.51 loss=4633.82  active=151132 feature_norm=103.60\n",
            "Iter 144 time=17.52 loss=4632.21  active=151041 feature_norm=103.58\n",
            "Iter 145 time=17.42 loss=4631.34  active=151102 feature_norm=103.62\n",
            "Iter 146 time=17.42 loss=4629.69  active=150997 feature_norm=103.61\n",
            "Iter 147 time=17.40 loss=4628.63  active=151023 feature_norm=103.65\n",
            "Iter 148 time=17.38 loss=4627.15  active=150903 feature_norm=103.64\n",
            "Iter 149 time=17.40 loss=4626.07  active=150928 feature_norm=103.67\n",
            "Iter 150 time=17.41 loss=4624.64  active=150682 feature_norm=103.66\n",
            "Iter 151 time=17.54 loss=4623.77  active=150813 feature_norm=103.70\n",
            "Iter 152 time=17.55 loss=4622.45  active=150685 feature_norm=103.69\n",
            "Iter 153 time=17.61 loss=4621.45  active=150759 feature_norm=103.73\n",
            "Iter 154 time=17.55 loss=4620.12  active=150515 feature_norm=103.72\n",
            "Iter 155 time=17.58 loss=4618.99  active=150520 feature_norm=103.76\n",
            "Iter 156 time=17.57 loss=4617.67  active=150410 feature_norm=103.75\n",
            "Iter 157 time=17.54 loss=4616.39  active=150262 feature_norm=103.78\n",
            "Iter 158 time=17.48 loss=4615.18  active=149945 feature_norm=103.77\n",
            "Iter 159 time=17.41 loss=4614.16  active=149862 feature_norm=103.81\n",
            "Iter 160 time=17.41 loss=4612.65  active=149673 feature_norm=103.79\n",
            "Iter 161 time=17.46 loss=4611.53  active=149717 feature_norm=103.83\n",
            "Iter 162 time=17.88 loss=4609.99  active=149491 feature_norm=103.81\n",
            "Iter 163 time=18.08 loss=4608.82  active=149453 feature_norm=103.84\n",
            "Iter 164 time=18.37 loss=4607.34  active=149196 feature_norm=103.83\n",
            "Iter 165 time=18.21 loss=4606.12  active=149244 feature_norm=103.86\n",
            "Iter 166 time=18.73 loss=4604.79  active=149134 feature_norm=103.85\n",
            "Iter 167 time=18.22 loss=4603.69  active=149027 feature_norm=103.88\n",
            "Iter 168 time=18.14 loss=4602.26  active=148869 feature_norm=103.86\n",
            "Iter 169 time=17.86 loss=4601.10  active=148782 feature_norm=103.90\n",
            "Iter 170 time=17.89 loss=4599.66  active=148714 feature_norm=103.89\n",
            "Iter 171 time=17.86 loss=4598.53  active=148784 feature_norm=103.92\n",
            "Iter 172 time=17.80 loss=4597.09  active=148469 feature_norm=103.91\n",
            "Iter 173 time=17.70 loss=4595.92  active=148324 feature_norm=103.94\n",
            "Iter 174 time=17.75 loss=4594.63  active=148089 feature_norm=103.93\n",
            "Iter 175 time=17.88 loss=4593.53  active=148099 feature_norm=103.96\n",
            "Iter 176 time=17.84 loss=4592.16  active=147838 feature_norm=103.95\n",
            "Iter 177 time=17.85 loss=4590.97  active=147958 feature_norm=103.98\n",
            "Iter 178 time=17.86 loss=4589.64  active=147781 feature_norm=103.97\n",
            "Iter 179 time=18.09 loss=4588.52  active=147969 feature_norm=104.00\n",
            "Iter 180 time=18.51 loss=4587.29  active=147855 feature_norm=103.99\n",
            "Iter 181 time=17.98 loss=4586.05  active=147941 feature_norm=104.02\n",
            "Iter 182 time=18.00 loss=4584.85  active=147864 feature_norm=104.01\n",
            "Iter 183 time=18.08 loss=4583.64  active=147932 feature_norm=104.03\n",
            "Iter 184 time=18.14 loss=4582.43  active=147814 feature_norm=104.02\n",
            "Iter 185 time=18.17 loss=4581.11  active=147784 feature_norm=104.03\n",
            "Iter 186 time=17.72 loss=4579.97  active=147655 feature_norm=104.02\n",
            "Iter 187 time=17.85 loss=4578.75  active=147723 feature_norm=104.03\n",
            "Iter 188 time=17.98 loss=4577.59  active=147516 feature_norm=104.01\n",
            "Iter 189 time=17.89 loss=4576.31  active=147691 feature_norm=104.03\n",
            "Iter 190 time=17.89 loss=4575.18  active=147546 feature_norm=104.00\n",
            "Iter 191 time=17.83 loss=4573.86  active=147547 feature_norm=104.02\n",
            "Iter 192 time=17.86 loss=4572.71  active=147449 feature_norm=103.99\n",
            "Iter 193 time=18.10 loss=4571.44  active=147536 feature_norm=104.00\n",
            "Iter 194 time=17.79 loss=4570.40  active=147290 feature_norm=103.97\n",
            "Iter 195 time=17.75 loss=4569.14  active=147350 feature_norm=103.98\n",
            "Iter 196 time=17.94 loss=4568.07  active=147130 feature_norm=103.96\n",
            "Iter 197 time=17.73 loss=4566.85  active=147169 feature_norm=103.96\n",
            "Iter 198 time=17.65 loss=4565.84  active=147060 feature_norm=103.93\n",
            "Iter 199 time=17.66 loss=4564.56  active=147036 feature_norm=103.94\n",
            "Iter 200 time=17.64 loss=4563.54  active=146925 feature_norm=103.91\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 3660.459\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 146925 (647667)\n",
            "Number of active attributes: 73150 (504219)\n",
            "Number of active labels: 37 (37)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.123\n",
            "\n",
            "CPU times: user 1h 2min 51s, sys: 26.2 s, total: 1h 3min 17s\n",
            "Wall time: 1h 2min 54s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#Train a CRF Model\n",
        "crf = CRF(algorithm='lbfgs',\n",
        "          c1=0.1,\n",
        "          c2=0.1,\n",
        "          max_iterations=200,\n",
        "          all_possible_transitions=True,\n",
        "          verbose=True)\n",
        "# Train the CRF model on the supplied training data\n",
        "crf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGU5UwMY24y4"
      },
      "outputs": [],
      "source": [
        "labels = list(crf.classes_)\n",
        "labels.remove('O')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGIQZUHz24y4",
        "outputId": "305a4f32-d953-4c3c-e7d2-dfd856c60162",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8657741211968164"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "y_pred = crf.predict(X_test)\n",
        "metrics.flat_f1_score(y_test, y_pred,\n",
        "                      average='weighted', labels=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2DHGZOT24y5"
      },
      "outputs": [],
      "source": [
        "# group B and I results\n",
        "sorted_labels = sorted(\n",
        "    labels,\n",
        "    key=lambda name: (name[1:], name[0])\n",
        ")\n",
        "print(metrics.flat_classification_report(\n",
        "    y_test, y_pred, labels=sorted_labels, digits=3\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV1X3Npi24y5"
      },
      "outputs": [],
      "source": [
        "def  chunk_extract(tag_list,sentence_id):\n",
        "  \"\"\"\n",
        "  >>> chunk_extract(['O', 'B-PER', 'I-PER', 'B-ORG', 'O'], 1)\n",
        "  [(1, 1, 3, 'PER'), (1, 3, 4, 'ORG')]\n",
        "  \"\"\"\n",
        "  nes = []\n",
        "  for i, tag in enumerate(tag_list):\n",
        "    if tag[0] == 'B':\n",
        "        ner_type = tag[2:]\n",
        "        if i < len(tag_list)-1:  \n",
        "            current = i + 1\n",
        "            if tag_list[current] == 'O':\n",
        "                nes.append((sentence_id,i,i, ner_type)) \n",
        "            elif tag_list[current] == 'I-{}'.format(ner_type):    \n",
        "                while tag_list[current] == 'I-{}'.format(ner_type) and current < (len(tag_list)-1):\n",
        "                    current += 1\n",
        "                nes.append((sentence_id,i, current, ner_type))\n",
        "        else:\n",
        "            nes.append((sentence_id,i,i, ner_type))\n",
        "  return nes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ir5TsDb24y5"
      },
      "outputs": [],
      "source": [
        "sentence_id = [x for x in range(len(y_test))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo7kXolh24y5",
        "outputId": "adf7b6d1-95bd-41ec-8c43-ace5b5521a35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5617it [00:00, 175214.98it/s]\n"
          ]
        }
      ],
      "source": [
        "chunk_test = set()\n",
        "error_id = []\n",
        "for sent,idx in tqdm(zip(y_test,sentence_id)):\n",
        "    ch = chunk_extract(sent,idx)\n",
        "    chunk_test.update(ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrvlJIie24y5",
        "outputId": "9227cfed-c0d2-4ba7-b094-bfec550f88fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5617it [00:00, 145095.25it/s]\n"
          ]
        }
      ],
      "source": [
        "chunk_pred = set()\n",
        "error_id = []\n",
        "for sent,idx in tqdm(zip(y_pred,sentence_id)):\n",
        "    ch = chunk_extract(sent,idx)\n",
        "    chunk_pred.update(ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxxLpE0R24y6"
      },
      "outputs": [],
      "source": [
        "def evaluation_phrase(true,prediction):\n",
        "    total_correct = len(true.intersection(prediction))\n",
        "    total_predict = len(prediction)\n",
        "    total_true = len(true)\n",
        "    \n",
        "    precision = total_correct/total_predict\n",
        "    recall = total_correct/total_true\n",
        "    f1 = (2 * precision * recall)/(precision + recall)\n",
        "    \n",
        "    print('total_correct:',total_correct,':','total_predict:',total_predict,':','total_true:',total_true)\n",
        "    print('precision:', round(precision,3))\n",
        "    print('recall:', round(recall,3))\n",
        "    print('f1:', round(f1,3))\n",
        "    return [round(precision,3),round(recall,3),round(f1,3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xo605af24y6",
        "outputId": "8225de0a-7819-47f2-94a8-1754cdb27e01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_correct: 928 : total_predict: 1026 : total_true: 1129\n",
            "precision: 0.904\n",
            "recall: 0.822\n",
            "f1: 0.861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.904, 0.822, 0.861]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "evaluation_phrase(chunk_test,chunk_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prIDivXO24y6"
      },
      "outputs": [],
      "source": [
        "def evaluation_phrase_type(chunk_test,chunk_pred):\n",
        "    total_pred, total_true, total_correct = 0, 0, 0\n",
        "    df = pd.DataFrame(columns=['PRECISION','RECALL','F1','SUPPORT'])\n",
        "    ent_types = ['ACP','ADMIN','BSN','DEP','FPLACE','GOV','HP','MKT','MON','NAT','OTHER','RCT','RES','ROAD','RP','RT','STORE','TRAN']\n",
        "    list_correct = []\n",
        "    for ent in ent_types:\n",
        "        true_set = []\n",
        "        pred_set = []\n",
        "        type_pred,type_true,type_correct = 0,0,0\n",
        "        for tag in chunk_test:\n",
        "            if tag[3] == ent:\n",
        "                true_set.append(tag)\n",
        "            if ent in tag:\n",
        "                type_true+=1\n",
        "                tag_true = set(true_set)\n",
        "        for tag2 in chunk_pred:\n",
        "            if tag2[3] == ent:\n",
        "                pred_set.append(tag2)\n",
        "            if ent in tag2:\n",
        "                type_pred+=1\n",
        "                tag_pred = set(pred_set)\n",
        "        type_correct=len(tag_true.intersection(tag_pred))\n",
        "        try:\n",
        "            precision = type_correct/type_pred\n",
        "        except:\n",
        "            precision = 0\n",
        "        recall = type_correct/type_true\n",
        "        try:\n",
        "            f1 = (2 * precision * recall) / (precision + recall)\n",
        "        except:\n",
        "            f1 = 0\n",
        "        list_correct.append([type_true,type_pred,type_correct,ent])\n",
        "        df.loc[ent] = [round(precision,3), round(recall,3), round(f1,3), str(type_true)]\n",
        "\n",
        "    #Calculate micro macro f1\n",
        "    total_true,total_pred,total_correct = 0,0,0\n",
        "    for p in list_correct:\n",
        "        total_true+=p[0]\n",
        "        total_pred+=p[1]\n",
        "        total_correct+=p[2]\n",
        "    precision_micro = total_correct / total_pred\n",
        "    recall_micro = total_correct / total_true\n",
        "    f1_micro = (2 * precision_micro * recall_micro) / (precision_micro + recall_micro)\n",
        "    df.loc['MACRO'] = [round(df.PRECISION.mean(),3), round(df.RECALL.mean(),3), round(df.F1.mean(),3), str(total_true)]\n",
        "    df.loc['MICRO'] = [round(precision_micro,3), round(recall_micro,3), round(f1_micro,3), str(total_true)]\n",
        "\n",
        "    print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbLSLImg24y6"
      },
      "outputs": [],
      "source": [
        "chunk_test = list(chunk_test)\n",
        "chunk_pred = list(chunk_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unxtfm5R24y6",
        "outputId": "bb6d7444-565d-429d-ab88-28a8cc4e3b80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        PRECISION  RECALL     F1 SUPPORT\n",
            "ACP         0.906   0.784  0.841      37\n",
            "ADMIN       0.934   0.916  0.925     309\n",
            "BSN         0.913   0.808  0.857      26\n",
            "DEP         0.872   0.728  0.794     103\n",
            "FPLACE      0.948   0.737  0.830      99\n",
            "GOV         1.000   0.680  0.810      25\n",
            "HP          0.900   0.750  0.818      24\n",
            "MKT         0.947   1.000  0.973      18\n",
            "MON         1.000   0.500  0.667       2\n",
            "NAT         1.000   0.909  0.952      11\n",
            "OTHER       1.000   1.000  1.000       3\n",
            "RCT         0.821   0.727  0.771      44\n",
            "RES         0.920   0.767  0.836      30\n",
            "ROAD        0.896   0.832  0.863     155\n",
            "RP          0.909   0.784  0.842      51\n",
            "RT          0.838   0.845  0.842     129\n",
            "STORE       0.895   0.708  0.791      24\n",
            "TRAN        0.882   0.769  0.822      39\n",
            "MACRO       0.921   0.791  0.846    1129\n",
            "MICRO       0.904   0.822  0.861    1129\n"
          ]
        }
      ],
      "source": [
        "evaluation_phrase_type(chunk_test,chunk_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDThlkAV24y6"
      },
      "outputs": [],
      "source": [
        "#save model\n",
        "with open(r'D:\\TEXT DATA\\TrainingData\\3.Model\\1.14CRF_attacut_Quadigram_PartOfGazetter+ExactMatch.model', 'wb') as model:\n",
        "    pickle.dump(crf,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctdfT3zA24y7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}