{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crescendonow/thai_geoparsing/blob/main/toponym_colab/IJG_1_CRF_pythainlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "!pip install pickle-mixin\n",
        "!pip install sklearn_crfsuite\n",
        "!pip install pythainlp[full]"
      ],
      "metadata": {
        "id": "6bc8Htxw3MEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1IFvYbu24yw"
      },
      "outputs": [],
      "source": [
        "#library for use\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "import pickle\n",
        "import codecs\n",
        "from itertools import chain\n",
        "\n",
        "#nlp library\n",
        "from pythainlp import word_tokenize, Tokenizer\n",
        "from pythainlp.tag import pos_tag, pos_tag_sents\n",
        "from pythainlp.corpus.common import thai_stopwords\n",
        "stopwords = thai_stopwords()\n",
        "from pythainlp.util import isthai, isthaichar, normalize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "#Mange data with scikit-learn\n",
        "import sklearn_crfsuite\n",
        "from collections import Counter\n",
        "from sklearn_crfsuite import CRF\n",
        "from sklearn_crfsuite import scorers,metrics\n",
        "from sklearn.metrics import make_scorer, classification_report\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import cross_validate, train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbaFPRe_4yN2",
        "outputId": "32d76fdb-2114-49e8-cd12-771de10d3343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9eJgS3A24yz"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/1.Tokennization/train_attacut_cl.data', 'rb') as token:\n",
        "    train_data = pickle.load(token)\n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/1.Tokennization/test_attacut_cl.data', 'rb') as token2:\n",
        "    test_data = pickle.load(token2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#feature from word space \n",
        "def is_space(word):\n",
        "    if word == ' ' or word == '\\t' or word == '':\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def is_stopword(word):\n",
        "    return word in stopwords"
      ],
      "metadata": {
        "id": "4H80OmNjMRm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYkjrb0g24y1"
      },
      "outputs": [],
      "source": [
        "def word_features(sentence,i):\n",
        "    word = sentence[i][0]\n",
        "    pos = sentence[i][1]\n",
        "        \n",
        "    #create feature in current word\n",
        "    features = {\n",
        "                    'bias': 1.0, \n",
        "                    'word': word,\n",
        "                    'word.is_stopword' : is_stopword(word),\n",
        "                    'word.isthai' : isthai(word),\n",
        "                    'word.is_space()': is_space(word),\n",
        "                    'postag': pos,\n",
        "                    'word.isdigit()': word.isdigit()\n",
        "                }\n",
        "        #If this is not the first word of sentence \n",
        "    if i > 0:\n",
        "        prev_word = sentence[i-1][0]\n",
        "        prev_pos = sentence[i-1][1]\n",
        "        features.update({\n",
        "                            '-1:word' : prev_word,\n",
        "                            '-1:word.is_stopword' : is_stopword(prev_word),\n",
        "                            '-1:word.isthai' : isthai(prev_word),\n",
        "                            '-1:word.is_space()': is_space(prev_word),\n",
        "                            '-1:postag': prev_pos,\n",
        "                            '-1:word.isdigit()': word.isdigit()\n",
        "                        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "        \n",
        "    if i < len(sentence)-1:\n",
        "        next_word = sentence[i+1][0]\n",
        "        next_pos = sentence[i+1][0]\n",
        "        features.update({\n",
        "                            '+1:word' : next_word,\n",
        "                            '+1:word.is_stopword' : is_stopword(next_word),\n",
        "                            '+1:word.isthai' : isthai(next_word),\n",
        "                            '+1:word.is_space()': is_space(next_word),\n",
        "                            '+1:postag': next_pos,\n",
        "                            '+1:word.isdigit()': word.isdigit()\n",
        "                        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "        \n",
        "    return features\n",
        "                \n",
        "#return feature dictionary for each word\n",
        "def sentence_features(sentence):\n",
        "    return [word_features(sentence,i) for i in range(len(sentence))]\n",
        "\n",
        "#return the label NER tags\n",
        "def sentence_labels(sentence):\n",
        "    return [label for token,pos,label in sentence]\n",
        "\n",
        "#return token \n",
        "def sentence_tokens(sentence):\n",
        "    return [token for token,pos,label in sentence]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwRt2Ztp24y3",
        "outputId": "4efeca49-b3fb-4cf7-ca21-8b4b918965a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/22445 [03:25<?, ?it/s]\n",
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 583/22445 [00:00<00:03, 5825.44it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  5%|▌         | 1166/22445 [00:00<00:03, 5370.72it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  8%|▊         | 1706/22445 [00:00<00:03, 5370.43it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 10%|█         | 2273/22445 [00:00<00:03, 5481.33it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 13%|█▎        | 2867/22445 [00:00<00:03, 5642.07it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 15%|█▌        | 3433/22445 [00:00<00:03, 5424.70it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 18%|█▊        | 3978/22445 [00:00<00:03, 5173.82it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 20%|██        | 4499/22445 [00:00<00:03, 4987.33it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 22%|██▏       | 5001/22445 [00:00<00:03, 4824.58it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 25%|██▍       | 5526/22445 [00:01<00:03, 4945.30it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 27%|██▋       | 6024/22445 [00:01<00:03, 4954.97it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 29%|██▉       | 6540/22445 [00:01<00:03, 5012.22it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 31%|███▏      | 7048/22445 [00:01<00:03, 5031.95it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 34%|███▎      | 7553/22445 [00:01<00:03, 4902.59it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 36%|███▌      | 8072/22445 [00:01<00:02, 4986.04it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 38%|███▊      | 8572/22445 [00:01<00:02, 4766.11it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 40%|████      | 9069/22445 [00:01<00:02, 4822.89it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 43%|████▎     | 9585/22445 [00:01<00:02, 4920.07it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 45%|████▍     | 10079/22445 [00:02<00:03, 3813.76it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 47%|████▋     | 10642/22445 [00:02<00:02, 4256.57it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 50%|████▉     | 11221/22445 [00:02<00:02, 4652.16it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 52%|█████▏    | 11760/22445 [00:02<00:02, 4849.40it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 55%|█████▍    | 12295/22445 [00:02<00:02, 4987.20it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 57%|█████▋    | 12814/22445 [00:02<00:01, 5043.53it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 59%|█████▉    | 13332/22445 [00:02<00:02, 4110.72it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 61%|██████▏   | 13780/22445 [00:02<00:02, 4121.82it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 64%|██████▍   | 14336/22445 [00:02<00:01, 4494.37it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 66%|██████▌   | 14810/22445 [00:03<00:01, 4553.73it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 68%|██████▊   | 15317/22445 [00:03<00:01, 4695.51it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 70%|███████   | 15800/22445 [00:03<00:01, 4666.13it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 73%|███████▎  | 16336/22445 [00:03<00:01, 4864.13it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 75%|███████▌  | 16887/22445 [00:03<00:01, 5048.41it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 78%|███████▊  | 17398/22445 [00:03<00:01, 5024.26it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 80%|███████▉  | 17905/22445 [00:03<00:00, 4914.29it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 82%|████████▏ | 18400/22445 [00:03<00:00, 4674.12it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 84%|████████▍ | 18891/22445 [00:03<00:00, 4739.74it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 86%|████████▋ | 19369/22445 [00:04<00:00, 4667.97it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 89%|████████▉ | 19955/22445 [00:04<00:00, 5008.96it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 91%|█████████ | 20459/22445 [00:04<00:00, 4772.96it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 94%|█████████▍| 21070/22445 [00:04<00:00, 5150.05it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 96%|█████████▌| 21602/22445 [00:04<00:00, 5196.37it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 22445/22445 [00:04<00:00, 4852.06it/s]\n",
            "100%|██████████| 5617/5617 [00:01<00:00, 5253.39it/s]\n",
            "100%|██████████| 22445/22445 [00:00<00:00, 200451.73it/s]\n",
            "100%|██████████| 5617/5617 [00:00<00:00, 174372.03it/s]\n",
            "100%|██████████| 22445/22445 [00:00<00:00, 200121.07it/s]\n",
            "100%|██████████| 5617/5617 [00:00<00:00, 169136.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.97 s, sys: 789 ms, total: 5.76 s\n",
            "Wall time: 6.07 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#Prepare word for train test\n",
        "X = [sentence_features(sentence) for sentence in tqdm(train_data)]\n",
        "X_test = [sentence_features(sentence) for sentence in tqdm(test_data)]\n",
        "\n",
        "#Label train test\n",
        "y = [sentence_labels(sentence) for sentence in tqdm(train_data)]\n",
        "y_test = [sentence_labels(sentence) for sentence in tqdm(test_data)]\n",
        "\n",
        "#Get token \n",
        "Train_token = [sentence_tokens(sentence) for sentence in tqdm(train_data)]\n",
        "Test_tokens = [sentence_tokens(sentence) for sentence in tqdm(test_data)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4_pNCgw24y3",
        "outputId": "39a5bf19-bf66-4540-ba84-8d3b38ed7763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading training data to CRFsuite: 100%|██████████| 22445/22445 [00:05<00:00, 3788.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 1\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 169881\n",
            "Seconds required: 1.101\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.100000\n",
            "c2: 0.100000\n",
            "num_memories: 6\n",
            "max_iterations: 500\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=6.39  loss=836948.09 active=169661 feature_norm=1.00\n",
            "Iter 2   time=3.28  loss=314019.62 active=169503 feature_norm=10.51\n",
            "Iter 3   time=3.33  loss=301539.00 active=166343 feature_norm=10.15\n",
            "Iter 4   time=45.96 loss=156177.06 active=51756 feature_norm=3.82\n",
            "Iter 5   time=6.66  loss=154419.73 active=107190 feature_norm=5.99\n",
            "Iter 6   time=3.33  loss=134715.17 active=95762 feature_norm=5.52\n",
            "Iter 7   time=20.13 loss=100369.52 active=91270 feature_norm=4.57\n",
            "Iter 8   time=22.83 loss=96193.66 active=65182 feature_norm=4.39\n",
            "Iter 9   time=17.93 loss=93274.94 active=88517 feature_norm=4.43\n",
            "Iter 10  time=3.36  loss=90236.71 active=87565 feature_norm=4.42\n",
            "Iter 11  time=3.29  loss=88888.42 active=88246 feature_norm=5.91\n",
            "Iter 12  time=3.37  loss=85750.46 active=84502 feature_norm=5.75\n",
            "Iter 13  time=3.27  loss=84235.88 active=86049 feature_norm=5.50\n",
            "Iter 14  time=6.51  loss=79553.69 active=84730 feature_norm=5.38\n",
            "Iter 15  time=3.25  loss=73653.81 active=85076 feature_norm=5.94\n",
            "Iter 16  time=9.84  loss=72601.60 active=84113 feature_norm=6.13\n",
            "Iter 17  time=3.26  loss=71518.30 active=85444 feature_norm=6.38\n",
            "Iter 18  time=3.32  loss=69527.90 active=82132 feature_norm=6.90\n",
            "Iter 19  time=3.22  loss=67175.48 active=82210 feature_norm=7.69\n",
            "Iter 20  time=3.23  loss=66013.36 active=78473 feature_norm=9.15\n",
            "Iter 21  time=3.27  loss=62721.33 active=81098 feature_norm=9.60\n",
            "Iter 22  time=3.25  loss=62149.47 active=80264 feature_norm=10.43\n",
            "Iter 23  time=3.34  loss=60230.06 active=80381 feature_norm=11.18\n",
            "Iter 24  time=3.29  loss=59472.73 active=79244 feature_norm=12.15\n",
            "Iter 25  time=3.34  loss=57462.86 active=77166 feature_norm=12.95\n",
            "Iter 26  time=3.36  loss=57097.13 active=76508 feature_norm=14.46\n",
            "Iter 27  time=3.40  loss=54593.46 active=77296 feature_norm=15.29\n",
            "Iter 28  time=3.37  loss=54506.70 active=76457 feature_norm=16.51\n",
            "Iter 29  time=3.24  loss=52196.48 active=76661 feature_norm=16.93\n",
            "Iter 30  time=3.29  loss=51203.59 active=75828 feature_norm=17.88\n",
            "Iter 31  time=3.32  loss=49493.74 active=75314 feature_norm=18.88\n",
            "Iter 32  time=6.50  loss=48010.58 active=74426 feature_norm=20.20\n",
            "Iter 33  time=3.26  loss=46009.19 active=73930 feature_norm=22.11\n",
            "Iter 34  time=6.48  loss=44393.16 active=72769 feature_norm=23.82\n",
            "Iter 35  time=3.31  loss=42438.72 active=72100 feature_norm=26.34\n",
            "Iter 36  time=3.25  loss=41101.48 active=70587 feature_norm=31.40\n",
            "Iter 37  time=3.21  loss=38581.15 active=71748 feature_norm=32.81\n",
            "Iter 38  time=3.25  loss=38029.01 active=70659 feature_norm=37.08\n",
            "Iter 39  time=3.24  loss=36536.97 active=70973 feature_norm=35.94\n",
            "Iter 40  time=3.33  loss=35874.72 active=70280 feature_norm=36.92\n",
            "Iter 41  time=4.19  loss=34560.21 active=69135 feature_norm=39.43\n",
            "Iter 42  time=7.43  loss=32868.52 active=66898 feature_norm=43.23\n",
            "Iter 43  time=3.39  loss=32712.88 active=63852 feature_norm=47.03\n",
            "Iter 44  time=3.24  loss=30990.91 active=64088 feature_norm=48.59\n",
            "Iter 45  time=6.45  loss=30082.39 active=63370 feature_norm=50.32\n",
            "Iter 46  time=3.32  loss=28838.58 active=62724 feature_norm=52.73\n",
            "Iter 47  time=6.50  loss=27328.96 active=60292 feature_norm=59.13\n",
            "Iter 48  time=6.52  loss=26027.40 active=59273 feature_norm=64.23\n",
            "Iter 49  time=3.27  loss=25201.84 active=58896 feature_norm=68.86\n",
            "Iter 50  time=3.34  loss=24351.85 active=58349 feature_norm=72.05\n",
            "Iter 51  time=3.35  loss=23688.00 active=58048 feature_norm=74.52\n",
            "Iter 52  time=6.61  loss=22465.19 active=56541 feature_norm=84.97\n",
            "Iter 53  time=9.99  loss=21694.84 active=56420 feature_norm=88.39\n",
            "Iter 54  time=3.31  loss=21395.47 active=56711 feature_norm=84.81\n",
            "Iter 55  time=3.32  loss=20873.85 active=56158 feature_norm=88.57\n",
            "Iter 56  time=3.27  loss=20020.09 active=56583 feature_norm=94.77\n",
            "Iter 57  time=3.32  loss=19101.12 active=55977 feature_norm=102.20\n",
            "Iter 58  time=3.29  loss=18169.61 active=55825 feature_norm=110.17\n",
            "Iter 59  time=3.27  loss=17152.91 active=55248 feature_norm=124.18\n",
            "Iter 60  time=3.29  loss=16323.92 active=55021 feature_norm=133.20\n",
            "Iter 61  time=3.25  loss=15633.73 active=54534 feature_norm=143.66\n",
            "Iter 62  time=3.37  loss=14912.35 active=53741 feature_norm=151.84\n",
            "Iter 63  time=3.41  loss=14278.97 active=52507 feature_norm=160.04\n",
            "Iter 64  time=3.34  loss=13924.56 active=50906 feature_norm=168.40\n",
            "Iter 65  time=3.32  loss=13624.51 active=50453 feature_norm=171.41\n",
            "Iter 66  time=3.29  loss=13346.60 active=49587 feature_norm=177.12\n",
            "Iter 67  time=6.57  loss=13208.18 active=48946 feature_norm=182.99\n",
            "Iter 68  time=3.36  loss=13022.66 active=48249 feature_norm=187.88\n",
            "Iter 69  time=3.43  loss=12939.85 active=48052 feature_norm=189.54\n",
            "Iter 70  time=3.47  loss=12842.40 active=47350 feature_norm=193.85\n",
            "Iter 71  time=3.30  loss=12772.43 active=46842 feature_norm=196.81\n",
            "Iter 72  time=3.46  loss=12724.33 active=46462 feature_norm=198.41\n",
            "Iter 73  time=3.42  loss=12677.85 active=45845 feature_norm=198.95\n",
            "Iter 74  time=4.57  loss=12646.44 active=45707 feature_norm=198.80\n",
            "Iter 75  time=3.65  loss=12608.21 active=45157 feature_norm=198.71\n",
            "Iter 76  time=3.31  loss=12558.62 active=44690 feature_norm=198.83\n",
            "Iter 77  time=3.30  loss=12486.75 active=43687 feature_norm=198.50\n",
            "Iter 78  time=3.40  loss=12449.92 active=42940 feature_norm=197.98\n",
            "Iter 79  time=3.41  loss=12400.65 active=42473 feature_norm=198.19\n",
            "Iter 80  time=3.35  loss=12364.02 active=42111 feature_norm=198.09\n",
            "Iter 81  time=3.34  loss=12312.20 active=41417 feature_norm=198.37\n",
            "Iter 82  time=3.30  loss=12281.95 active=41307 feature_norm=198.20\n",
            "Iter 83  time=3.36  loss=12254.53 active=40919 feature_norm=198.34\n",
            "Iter 84  time=3.31  loss=12220.06 active=40469 feature_norm=198.30\n",
            "Iter 85  time=3.38  loss=12193.64 active=40019 feature_norm=198.41\n",
            "Iter 86  time=3.28  loss=12167.32 active=39745 feature_norm=198.22\n",
            "Iter 87  time=3.41  loss=12143.17 active=39429 feature_norm=198.19\n",
            "Iter 88  time=3.34  loss=12121.91 active=39291 feature_norm=197.97\n",
            "Iter 89  time=3.37  loss=12102.48 active=39034 feature_norm=197.97\n",
            "Iter 90  time=3.32  loss=12084.73 active=38900 feature_norm=197.83\n",
            "Iter 91  time=3.27  loss=12069.10 active=38541 feature_norm=197.86\n",
            "Iter 92  time=3.32  loss=12054.74 active=38113 feature_norm=197.81\n",
            "Iter 93  time=3.29  loss=12043.32 active=37828 feature_norm=197.92\n",
            "Iter 94  time=3.35  loss=12032.55 active=37735 feature_norm=197.90\n",
            "Iter 95  time=3.28  loss=12021.97 active=37585 feature_norm=197.99\n",
            "Iter 96  time=3.35  loss=12012.44 active=37430 feature_norm=197.95\n",
            "Iter 97  time=3.32  loss=12004.51 active=37310 feature_norm=198.03\n",
            "Iter 98  time=3.31  loss=11997.01 active=37298 feature_norm=197.97\n",
            "Iter 99  time=3.28  loss=11989.83 active=37210 feature_norm=198.05\n",
            "Iter 100 time=3.28  loss=11983.39 active=37160 feature_norm=197.98\n",
            "Iter 101 time=3.29  loss=11977.87 active=37097 feature_norm=198.07\n",
            "Iter 102 time=3.30  loss=11971.99 active=37132 feature_norm=198.00\n",
            "Iter 103 time=3.34  loss=11966.55 active=37039 feature_norm=198.03\n",
            "Iter 104 time=3.29  loss=11960.36 active=36990 feature_norm=197.95\n",
            "Iter 105 time=3.49  loss=11955.69 active=36957 feature_norm=198.01\n",
            "Iter 106 time=3.60  loss=11950.74 active=36936 feature_norm=197.91\n",
            "Iter 107 time=3.39  loss=11946.86 active=36885 feature_norm=197.97\n",
            "Iter 108 time=3.31  loss=11942.65 active=36886 feature_norm=197.91\n",
            "Iter 109 time=3.33  loss=11939.02 active=36818 feature_norm=197.94\n",
            "Iter 110 time=3.29  loss=11935.22 active=36776 feature_norm=197.87\n",
            "Iter 111 time=3.28  loss=11932.13 active=36725 feature_norm=197.94\n",
            "Iter 112 time=3.34  loss=11928.58 active=36713 feature_norm=197.88\n",
            "Iter 113 time=3.26  loss=11925.61 active=36679 feature_norm=197.93\n",
            "Iter 114 time=3.31  loss=11922.34 active=36653 feature_norm=197.89\n",
            "Iter 115 time=4.97  loss=11919.60 active=36588 feature_norm=197.94\n",
            "Iter 116 time=3.32  loss=11916.81 active=36560 feature_norm=197.86\n",
            "Iter 117 time=3.32  loss=11913.84 active=36550 feature_norm=197.94\n",
            "Iter 118 time=3.29  loss=11911.27 active=36566 feature_norm=197.89\n",
            "Iter 119 time=3.35  loss=11908.98 active=36550 feature_norm=197.93\n",
            "Iter 120 time=3.35  loss=11906.86 active=36538 feature_norm=197.89\n",
            "Iter 121 time=3.35  loss=11904.85 active=36526 feature_norm=197.93\n",
            "Iter 122 time=3.30  loss=11902.60 active=36517 feature_norm=197.90\n",
            "Iter 123 time=3.40  loss=11900.65 active=36495 feature_norm=197.94\n",
            "Iter 124 time=3.35  loss=11898.66 active=36490 feature_norm=197.90\n",
            "Iter 125 time=3.35  loss=11896.97 active=36448 feature_norm=197.95\n",
            "Iter 126 time=3.35  loss=11895.26 active=36444 feature_norm=197.92\n",
            "Iter 127 time=3.29  loss=11893.47 active=36425 feature_norm=197.96\n",
            "Iter 128 time=3.28  loss=11891.78 active=36415 feature_norm=197.93\n",
            "Iter 129 time=3.33  loss=11890.08 active=36400 feature_norm=197.96\n",
            "Iter 130 time=3.31  loss=11888.66 active=36408 feature_norm=197.93\n",
            "Iter 131 time=3.28  loss=11887.32 active=36380 feature_norm=197.97\n",
            "Iter 132 time=3.34  loss=11885.63 active=36372 feature_norm=197.94\n",
            "Iter 133 time=3.31  loss=11884.27 active=36348 feature_norm=197.97\n",
            "Iter 134 time=3.33  loss=11882.65 active=36354 feature_norm=197.95\n",
            "Iter 135 time=3.34  loss=11881.55 active=36346 feature_norm=197.97\n",
            "Iter 136 time=3.27  loss=11879.99 active=36334 feature_norm=197.95\n",
            "Iter 137 time=3.37  loss=11879.13 active=36300 feature_norm=197.97\n",
            "Iter 138 time=3.33  loss=11877.59 active=36300 feature_norm=197.95\n",
            "Iter 139 time=3.35  loss=11876.90 active=36296 feature_norm=197.98\n",
            "Iter 140 time=3.46  loss=11875.19 active=36293 feature_norm=197.96\n",
            "Iter 141 time=3.42  loss=11874.49 active=36265 feature_norm=197.97\n",
            "Iter 142 time=3.37  loss=11872.97 active=36261 feature_norm=197.96\n",
            "Iter 143 time=3.40  loss=11872.45 active=36254 feature_norm=197.97\n",
            "Iter 144 time=3.34  loss=11870.86 active=36235 feature_norm=197.95\n",
            "Iter 145 time=3.32  loss=11870.57 active=36207 feature_norm=197.97\n",
            "Iter 146 time=3.32  loss=11868.77 active=36207 feature_norm=197.96\n",
            "Iter 147 time=3.28  loss=11868.34 active=36206 feature_norm=197.97\n",
            "Iter 148 time=3.27  loss=11866.76 active=36184 feature_norm=197.96\n",
            "Iter 149 time=3.37  loss=11866.46 active=36173 feature_norm=197.98\n",
            "Iter 150 time=3.40  loss=11864.87 active=36181 feature_norm=197.97\n",
            "Iter 151 time=3.26  loss=11864.64 active=36155 feature_norm=197.98\n",
            "Iter 152 time=3.25  loss=11863.07 active=36169 feature_norm=197.97\n",
            "Iter 153 time=3.31  loss=11862.95 active=36146 feature_norm=197.98\n",
            "Iter 154 time=3.29  loss=11861.19 active=36157 feature_norm=197.97\n",
            "Iter 155 time=3.55  loss=11861.14 active=36140 feature_norm=197.99\n",
            "Iter 156 time=4.81  loss=11859.37 active=36125 feature_norm=197.98\n",
            "Iter 157 time=6.79  loss=11858.53 active=36131 feature_norm=197.98\n",
            "Iter 158 time=3.49  loss=11857.29 active=36113 feature_norm=197.97\n",
            "Iter 159 time=6.65  loss=11855.93 active=36108 feature_norm=197.98\n",
            "Iter 160 time=6.59  loss=11854.70 active=36122 feature_norm=197.97\n",
            "Iter 161 time=6.65  loss=11853.80 active=36098 feature_norm=197.98\n",
            "Iter 162 time=6.51  loss=11852.17 active=36100 feature_norm=197.96\n",
            "Iter 163 time=6.79  loss=11851.23 active=36102 feature_norm=197.97\n",
            "Iter 164 time=6.73  loss=11849.42 active=36096 feature_norm=197.95\n",
            "Iter 165 time=6.72  loss=11848.41 active=36094 feature_norm=197.95\n",
            "Iter 166 time=6.56  loss=11846.98 active=36077 feature_norm=197.94\n",
            "Iter 167 time=6.75  loss=11845.94 active=36053 feature_norm=197.94\n",
            "Iter 168 time=6.53  loss=11844.37 active=36055 feature_norm=197.92\n",
            "Iter 169 time=6.60  loss=11843.53 active=36033 feature_norm=197.92\n",
            "Iter 170 time=6.52  loss=11841.81 active=36028 feature_norm=197.90\n",
            "Iter 171 time=6.55  loss=11840.90 active=36026 feature_norm=197.90\n",
            "Iter 172 time=6.56  loss=11839.39 active=36022 feature_norm=197.88\n",
            "Iter 173 time=6.45  loss=11838.60 active=36006 feature_norm=197.88\n",
            "Iter 174 time=6.49  loss=11837.05 active=36004 feature_norm=197.86\n",
            "Iter 175 time=6.51  loss=11836.14 active=35986 feature_norm=197.86\n",
            "Iter 176 time=6.73  loss=11834.74 active=35985 feature_norm=197.83\n",
            "Iter 177 time=8.25  loss=11833.99 active=35964 feature_norm=197.82\n",
            "Iter 178 time=6.60  loss=11832.43 active=35962 feature_norm=197.79\n",
            "Iter 179 time=6.56  loss=11831.43 active=35941 feature_norm=197.78\n",
            "Iter 180 time=6.57  loss=11830.12 active=35928 feature_norm=197.75\n",
            "Iter 181 time=6.59  loss=11829.12 active=35928 feature_norm=197.75\n",
            "Iter 182 time=6.63  loss=11827.76 active=35932 feature_norm=197.71\n",
            "Iter 183 time=6.60  loss=11826.81 active=35927 feature_norm=197.70\n",
            "Iter 184 time=6.61  loss=11825.47 active=35926 feature_norm=197.67\n",
            "Iter 185 time=6.72  loss=11824.57 active=35930 feature_norm=197.66\n",
            "Iter 186 time=6.76  loss=11823.30 active=35923 feature_norm=197.63\n",
            "Iter 187 time=6.78  loss=11822.49 active=35906 feature_norm=197.62\n",
            "Iter 188 time=6.61  loss=11821.23 active=35915 feature_norm=197.59\n",
            "Iter 189 time=6.69  loss=11820.36 active=35905 feature_norm=197.59\n",
            "Iter 190 time=6.66  loss=11819.06 active=35910 feature_norm=197.55\n",
            "Iter 191 time=6.65  loss=11818.27 active=35874 feature_norm=197.54\n",
            "Iter 192 time=6.76  loss=11816.88 active=35860 feature_norm=197.50\n",
            "Iter 193 time=6.58  loss=11816.04 active=35863 feature_norm=197.50\n",
            "Iter 194 time=6.76  loss=11814.85 active=35853 feature_norm=197.47\n",
            "Iter 195 time=6.81  loss=11814.19 active=35830 feature_norm=197.47\n",
            "Iter 196 time=6.69  loss=11812.94 active=35820 feature_norm=197.44\n",
            "Iter 197 time=7.59  loss=11812.28 active=35821 feature_norm=197.44\n",
            "Iter 198 time=7.30  loss=11811.17 active=35814 feature_norm=197.42\n",
            "Iter 199 time=6.74  loss=11810.62 active=35804 feature_norm=197.42\n",
            "Iter 200 time=6.66  loss=11809.41 active=35793 feature_norm=197.40\n",
            "Iter 201 time=6.53  loss=11808.87 active=35787 feature_norm=197.40\n",
            "Iter 202 time=6.81  loss=11807.77 active=35789 feature_norm=197.38\n",
            "Iter 203 time=6.88  loss=11807.41 active=35783 feature_norm=197.38\n",
            "Iter 204 time=6.77  loss=11806.18 active=35791 feature_norm=197.36\n",
            "Iter 205 time=6.71  loss=11805.45 active=35779 feature_norm=197.36\n",
            "Iter 206 time=6.73  loss=11804.57 active=35783 feature_norm=197.35\n",
            "Iter 207 time=6.92  loss=11804.23 active=35767 feature_norm=197.35\n",
            "Iter 208 time=6.76  loss=11802.78 active=35758 feature_norm=197.33\n",
            "Iter 209 time=6.70  loss=11802.25 active=35759 feature_norm=197.33\n",
            "Iter 210 time=6.72  loss=11801.23 active=35750 feature_norm=197.32\n",
            "Iter 211 time=6.81  loss=11800.94 active=35737 feature_norm=197.32\n",
            "Iter 212 time=6.71  loss=11799.62 active=35748 feature_norm=197.31\n",
            "Iter 213 time=3.42  loss=11799.51 active=35730 feature_norm=197.31\n",
            "Iter 214 time=3.37  loss=11797.93 active=35760 feature_norm=197.28\n",
            "Iter 215 time=6.55  loss=11796.47 active=35777 feature_norm=197.29\n",
            "Iter 216 time=3.25  loss=11796.01 active=35762 feature_norm=197.28\n",
            "Iter 217 time=6.64  loss=11794.58 active=35774 feature_norm=197.29\n",
            "Iter 218 time=6.54  loss=11793.83 active=35815 feature_norm=197.28\n",
            "Iter 219 time=8.21  loss=11793.56 active=35794 feature_norm=197.28\n",
            "Iter 220 time=6.62  loss=11792.37 active=35805 feature_norm=197.27\n",
            "Iter 221 time=6.65  loss=11792.10 active=35800 feature_norm=197.28\n",
            "Iter 222 time=6.72  loss=11790.90 active=35796 feature_norm=197.26\n",
            "Iter 223 time=6.70  loss=11790.52 active=35790 feature_norm=197.27\n",
            "Iter 224 time=6.59  loss=11789.74 active=35800 feature_norm=197.25\n",
            "Iter 225 time=6.61  loss=11789.37 active=35784 feature_norm=197.26\n",
            "Iter 226 time=6.61  loss=11788.49 active=35777 feature_norm=197.25\n",
            "Iter 227 time=6.60  loss=11788.19 active=35750 feature_norm=197.25\n",
            "Iter 228 time=6.62  loss=11787.31 active=35740 feature_norm=197.24\n",
            "Iter 229 time=6.80  loss=11786.92 active=35734 feature_norm=197.24\n",
            "Iter 230 time=6.75  loss=11786.12 active=35735 feature_norm=197.23\n",
            "Iter 231 time=6.84  loss=11785.77 active=35734 feature_norm=197.23\n",
            "Iter 232 time=6.70  loss=11784.93 active=35729 feature_norm=197.22\n",
            "Iter 233 time=6.76  loss=11784.62 active=35729 feature_norm=197.23\n",
            "Iter 234 time=6.60  loss=11783.72 active=35736 feature_norm=197.21\n",
            "Iter 235 time=6.60  loss=11783.38 active=35730 feature_norm=197.22\n",
            "Iter 236 time=6.75  loss=11782.53 active=35725 feature_norm=197.21\n",
            "Iter 237 time=6.62  loss=11782.05 active=35710 feature_norm=197.21\n",
            "Iter 238 time=6.57  loss=11781.33 active=35711 feature_norm=197.20\n",
            "Iter 239 time=6.85  loss=11781.02 active=35707 feature_norm=197.20\n",
            "Iter 240 time=8.44  loss=11780.05 active=35707 feature_norm=197.19\n",
            "Iter 241 time=6.72  loss=11779.78 active=35696 feature_norm=197.19\n",
            "Iter 242 time=7.11  loss=11778.88 active=35675 feature_norm=197.18\n",
            "Iter 243 time=7.76  loss=11778.60 active=35667 feature_norm=197.19\n",
            "Iter 244 time=7.22  loss=11777.71 active=35656 feature_norm=197.17\n",
            "Iter 245 time=6.48  loss=11777.41 active=35662 feature_norm=197.18\n",
            "Iter 246 time=6.54  loss=11776.59 active=35647 feature_norm=197.16\n",
            "Iter 247 time=6.64  loss=11776.29 active=35654 feature_norm=197.16\n",
            "Iter 248 time=6.54  loss=11775.48 active=35647 feature_norm=197.15\n",
            "Iter 249 time=6.61  loss=11775.28 active=35632 feature_norm=197.16\n",
            "Iter 250 time=6.49  loss=11774.38 active=35618 feature_norm=197.14\n",
            "Iter 251 time=6.42  loss=11774.02 active=35611 feature_norm=197.15\n",
            "Iter 252 time=6.56  loss=11773.35 active=35596 feature_norm=197.14\n",
            "Iter 253 time=6.49  loss=11773.18 active=35586 feature_norm=197.14\n",
            "Iter 254 time=6.50  loss=11772.26 active=35578 feature_norm=197.13\n",
            "Iter 255 time=6.41  loss=11771.91 active=35564 feature_norm=197.13\n",
            "Iter 256 time=6.42  loss=11771.23 active=35551 feature_norm=197.12\n",
            "Iter 257 time=6.84  loss=11771.00 active=35534 feature_norm=197.12\n",
            "Iter 258 time=6.66  loss=11770.13 active=35530 feature_norm=197.11\n",
            "Iter 259 time=6.55  loss=11769.85 active=35524 feature_norm=197.12\n",
            "Iter 260 time=6.43  loss=11769.19 active=35522 feature_norm=197.11\n",
            "Iter 261 time=6.49  loss=11769.02 active=35519 feature_norm=197.11\n",
            "Iter 262 time=8.20  loss=11768.16 active=35504 feature_norm=197.10\n",
            "Iter 263 time=6.39  loss=11767.86 active=35495 feature_norm=197.10\n",
            "Iter 264 time=6.43  loss=11767.26 active=35491 feature_norm=197.10\n",
            "Iter 265 time=6.54  loss=11767.17 active=35478 feature_norm=197.10\n",
            "Iter 266 time=6.65  loss=11766.23 active=35476 feature_norm=197.09\n",
            "Iter 267 time=6.80  loss=11766.04 active=35470 feature_norm=197.10\n",
            "Iter 268 time=6.62  loss=11765.32 active=35472 feature_norm=197.09\n",
            "Iter 269 time=6.53  loss=11765.25 active=35450 feature_norm=197.10\n",
            "Iter 270 time=6.43  loss=11764.38 active=35445 feature_norm=197.09\n",
            "Iter 271 time=6.65  loss=11764.01 active=35433 feature_norm=197.09\n",
            "Iter 272 time=6.44  loss=11763.55 active=35441 feature_norm=197.08\n",
            "Iter 273 time=6.41  loss=11763.38 active=35427 feature_norm=197.09\n",
            "Iter 274 time=6.49  loss=11762.47 active=35437 feature_norm=197.08\n",
            "Iter 275 time=6.46  loss=11762.31 active=35426 feature_norm=197.09\n",
            "Iter 276 time=6.67  loss=11761.61 active=35407 feature_norm=197.08\n",
            "Iter 277 time=6.54  loss=11761.48 active=35410 feature_norm=197.09\n",
            "Iter 278 time=3.28  loss=11761.43 active=35398 feature_norm=197.07\n",
            "Iter 279 time=3.24  loss=11760.62 active=35401 feature_norm=197.09\n",
            "Iter 280 time=3.20  loss=11759.80 active=35411 feature_norm=197.08\n",
            "Iter 281 time=3.26  loss=11759.62 active=35403 feature_norm=197.09\n",
            "Iter 282 time=3.23  loss=11758.64 active=35410 feature_norm=197.08\n",
            "Iter 283 time=3.22  loss=11758.64 active=35414 feature_norm=197.09\n",
            "Iter 284 time=3.21  loss=11757.79 active=35417 feature_norm=197.08\n",
            "Iter 285 time=6.51  loss=11757.44 active=35426 feature_norm=197.08\n",
            "Iter 286 time=3.33  loss=11757.39 active=35419 feature_norm=197.08\n",
            "Iter 287 time=3.89  loss=11757.17 active=35412 feature_norm=197.08\n",
            "Iter 288 time=4.31  loss=11756.18 active=35428 feature_norm=197.08\n",
            "Iter 289 time=6.75  loss=11755.58 active=35427 feature_norm=197.08\n",
            "Iter 290 time=6.83  loss=11755.26 active=35430 feature_norm=197.08\n",
            "Iter 291 time=6.68  loss=11755.10 active=35425 feature_norm=197.08\n",
            "Iter 292 time=6.49  loss=11754.54 active=35429 feature_norm=197.07\n",
            "Iter 293 time=6.48  loss=11754.30 active=35424 feature_norm=197.08\n",
            "Iter 294 time=6.57  loss=11753.81 active=35421 feature_norm=197.07\n",
            "Iter 295 time=6.69  loss=11753.68 active=35425 feature_norm=197.07\n",
            "Iter 296 time=6.47  loss=11753.04 active=35422 feature_norm=197.07\n",
            "Iter 297 time=6.51  loss=11752.79 active=35401 feature_norm=197.07\n",
            "Iter 298 time=6.51  loss=11752.33 active=35382 feature_norm=197.06\n",
            "Iter 299 time=6.80  loss=11752.10 active=35373 feature_norm=197.06\n",
            "Iter 300 time=6.57  loss=11751.64 active=35369 feature_norm=197.06\n",
            "Iter 301 time=6.42  loss=11751.41 active=35351 feature_norm=197.06\n",
            "Iter 302 time=6.54  loss=11750.96 active=35343 feature_norm=197.06\n",
            "Iter 303 time=6.43  loss=11750.75 active=35340 feature_norm=197.06\n",
            "Iter 304 time=6.54  loss=11750.25 active=35332 feature_norm=197.05\n",
            "Iter 305 time=6.50  loss=11750.14 active=35322 feature_norm=197.05\n",
            "Iter 306 time=6.49  loss=11749.58 active=35319 feature_norm=197.05\n",
            "Iter 307 time=6.46  loss=11749.53 active=35305 feature_norm=197.05\n",
            "Iter 308 time=6.66  loss=11748.94 active=35299 feature_norm=197.04\n",
            "Iter 309 time=8.38  loss=11748.70 active=35290 feature_norm=197.04\n",
            "Iter 310 time=6.61  loss=11748.32 active=35287 feature_norm=197.04\n",
            "Iter 311 time=6.47  loss=11748.17 active=35295 feature_norm=197.04\n",
            "Iter 312 time=6.47  loss=11747.68 active=35298 feature_norm=197.03\n",
            "Iter 313 time=6.47  loss=11747.49 active=35297 feature_norm=197.03\n",
            "Iter 314 time=6.47  loss=11747.11 active=35297 feature_norm=197.02\n",
            "Iter 315 time=6.60  loss=11746.94 active=35290 feature_norm=197.02\n",
            "Iter 316 time=6.49  loss=11746.51 active=35280 feature_norm=197.02\n",
            "Iter 317 time=6.64  loss=11746.34 active=35269 feature_norm=197.02\n",
            "Iter 318 time=6.53  loss=11745.95 active=35257 feature_norm=197.01\n",
            "Iter 319 time=6.55  loss=11745.80 active=35261 feature_norm=197.01\n",
            "Iter 320 time=6.48  loss=11745.36 active=35258 feature_norm=197.01\n",
            "Iter 321 time=6.39  loss=11745.19 active=35254 feature_norm=197.01\n",
            "Iter 322 time=6.46  loss=11744.81 active=35244 feature_norm=197.00\n",
            "Iter 323 time=6.40  loss=11744.68 active=35237 feature_norm=197.01\n",
            "Iter 324 time=6.56  loss=11744.24 active=35228 feature_norm=197.00\n",
            "Iter 325 time=6.49  loss=11744.05 active=35209 feature_norm=197.00\n",
            "Iter 326 time=6.56  loss=11743.69 active=35240 feature_norm=196.99\n",
            "Iter 327 time=6.60  loss=11743.55 active=35222 feature_norm=196.99\n",
            "Iter 328 time=6.60  loss=11743.11 active=35220 feature_norm=196.99\n",
            "Iter 329 time=6.44  loss=11742.94 active=35210 feature_norm=196.99\n",
            "Iter 330 time=7.65  loss=11742.57 active=35204 feature_norm=196.98\n",
            "Iter 331 time=7.14  loss=11742.42 active=35218 feature_norm=196.98\n",
            "Iter 332 time=6.56  loss=11742.03 active=35212 feature_norm=196.98\n",
            "Iter 333 time=6.71  loss=11741.89 active=35208 feature_norm=196.98\n",
            "Iter 334 time=6.61  loss=11741.52 active=35210 feature_norm=196.97\n",
            "Iter 335 time=6.42  loss=11741.41 active=35203 feature_norm=196.97\n",
            "Iter 336 time=6.59  loss=11741.03 active=35202 feature_norm=196.97\n",
            "Iter 337 time=6.56  loss=11740.89 active=35193 feature_norm=196.97\n",
            "Iter 338 time=6.45  loss=11740.55 active=35191 feature_norm=196.96\n",
            "Iter 339 time=6.39  loss=11740.44 active=35184 feature_norm=196.97\n",
            "Iter 340 time=6.63  loss=11740.04 active=35179 feature_norm=196.96\n",
            "Iter 341 time=6.50  loss=11739.87 active=35167 feature_norm=196.96\n",
            "Iter 342 time=6.44  loss=11739.56 active=35162 feature_norm=196.96\n",
            "Iter 343 time=6.44  loss=11739.52 active=35156 feature_norm=196.96\n",
            "Iter 344 time=6.51  loss=11739.08 active=35156 feature_norm=196.95\n",
            "Iter 345 time=6.56  loss=11738.92 active=35156 feature_norm=196.95\n",
            "Iter 346 time=6.46  loss=11738.66 active=35145 feature_norm=196.95\n",
            "Iter 347 time=6.53  loss=11738.49 active=35141 feature_norm=196.95\n",
            "Iter 348 time=6.50  loss=11738.20 active=35133 feature_norm=196.95\n",
            "Iter 349 time=6.61  loss=11738.06 active=35132 feature_norm=196.95\n",
            "Iter 350 time=6.46  loss=11737.77 active=35127 feature_norm=196.95\n",
            "Iter 351 time=6.50  loss=11737.60 active=35117 feature_norm=196.95\n",
            "Iter 352 time=8.14  loss=11737.35 active=35120 feature_norm=196.95\n",
            "Iter 353 time=6.51  loss=11737.22 active=35102 feature_norm=196.95\n",
            "Iter 354 time=6.67  loss=11736.97 active=35093 feature_norm=196.95\n",
            "Iter 355 time=6.43  loss=11736.86 active=35073 feature_norm=196.95\n",
            "Iter 356 time=6.50  loss=11736.58 active=35072 feature_norm=196.95\n",
            "Iter 357 time=6.49  loss=11736.48 active=35055 feature_norm=196.95\n",
            "Iter 358 time=6.46  loss=11736.17 active=35059 feature_norm=196.95\n",
            "Iter 359 time=6.43  loss=11736.15 active=35051 feature_norm=196.95\n",
            "Iter 360 time=6.51  loss=11735.79 active=35045 feature_norm=196.95\n",
            "Iter 361 time=6.41  loss=11735.70 active=35039 feature_norm=196.96\n",
            "Iter 362 time=6.49  loss=11735.42 active=35024 feature_norm=196.96\n",
            "Iter 363 time=6.66  loss=11735.36 active=35017 feature_norm=196.96\n",
            "Iter 364 time=6.55  loss=11735.04 active=35017 feature_norm=196.96\n",
            "Iter 365 time=6.58  loss=11734.99 active=35013 feature_norm=196.96\n",
            "Iter 366 time=6.47  loss=11734.67 active=35008 feature_norm=196.96\n",
            "Iter 367 time=6.37  loss=11734.63 active=35003 feature_norm=196.96\n",
            "Iter 368 time=6.47  loss=11734.32 active=34999 feature_norm=196.96\n",
            "Iter 369 time=6.51  loss=11734.20 active=34990 feature_norm=196.97\n",
            "Iter 370 time=6.47  loss=11734.00 active=34988 feature_norm=196.96\n",
            "Iter 371 time=6.50  loss=11733.92 active=34985 feature_norm=196.97\n",
            "Iter 372 time=6.45  loss=11733.63 active=34982 feature_norm=196.96\n",
            "Iter 373 time=8.23  loss=11733.48 active=34972 feature_norm=196.97\n",
            "Iter 374 time=6.46  loss=11733.29 active=34973 feature_norm=196.96\n",
            "Iter 375 time=6.43  loss=11733.21 active=34963 feature_norm=196.97\n",
            "Iter 376 time=6.44  loss=11732.92 active=34962 feature_norm=196.96\n",
            "Iter 377 time=6.43  loss=11732.84 active=34958 feature_norm=196.97\n",
            "Iter 378 time=6.49  loss=11732.59 active=34960 feature_norm=196.96\n",
            "Iter 379 time=6.50  loss=11732.57 active=34956 feature_norm=196.97\n",
            "Iter 380 time=6.59  loss=11732.25 active=34953 feature_norm=196.97\n",
            "Iter 381 time=6.59  loss=11732.16 active=34948 feature_norm=196.97\n",
            "Iter 382 time=6.58  loss=11731.97 active=34951 feature_norm=196.97\n",
            "Iter 383 time=6.52  loss=11731.89 active=34947 feature_norm=196.97\n",
            "Iter 384 time=6.56  loss=11731.65 active=34944 feature_norm=196.97\n",
            "Iter 385 time=6.47  loss=11731.51 active=34939 feature_norm=196.97\n",
            "Iter 386 time=6.50  loss=11731.36 active=34929 feature_norm=196.97\n",
            "Iter 387 time=6.52  loss=11731.27 active=34922 feature_norm=196.98\n",
            "Iter 388 time=6.46  loss=11731.00 active=34918 feature_norm=196.97\n",
            "Iter 389 time=6.47  loss=11730.94 active=34911 feature_norm=196.98\n",
            "Iter 390 time=6.58  loss=11730.70 active=34905 feature_norm=196.97\n",
            "Iter 391 time=6.59  loss=11730.66 active=34904 feature_norm=196.98\n",
            "Iter 392 time=6.53  loss=11730.40 active=34894 feature_norm=196.98\n",
            "Iter 393 time=6.50  loss=11730.28 active=34891 feature_norm=196.98\n",
            "Iter 394 time=6.49  loss=11730.13 active=34890 feature_norm=196.98\n",
            "Iter 395 time=8.12  loss=11730.05 active=34890 feature_norm=196.98\n",
            "Iter 396 time=6.47  loss=11729.81 active=34886 feature_norm=196.98\n",
            "Iter 397 time=6.46  loss=11729.71 active=34884 feature_norm=196.98\n",
            "Iter 398 time=6.45  loss=11729.53 active=34873 feature_norm=196.98\n",
            "Iter 399 time=6.42  loss=11729.41 active=34867 feature_norm=196.98\n",
            "Iter 400 time=6.67  loss=11729.24 active=34869 feature_norm=196.98\n",
            "Iter 401 time=6.63  loss=11729.16 active=34856 feature_norm=196.99\n",
            "Iter 402 time=6.52  loss=11728.97 active=34855 feature_norm=196.98\n",
            "Iter 403 time=6.46  loss=11728.91 active=34851 feature_norm=196.99\n",
            "Iter 404 time=6.59  loss=11728.69 active=34841 feature_norm=196.98\n",
            "Iter 405 time=6.49  loss=11728.63 active=34842 feature_norm=196.98\n",
            "Iter 406 time=6.42  loss=11728.42 active=34836 feature_norm=196.98\n",
            "Iter 407 time=6.46  loss=11728.35 active=34827 feature_norm=196.98\n",
            "Iter 408 time=6.62  loss=11728.17 active=34831 feature_norm=196.98\n",
            "Iter 409 time=6.53  loss=11728.13 active=34832 feature_norm=196.98\n",
            "Iter 410 time=6.51  loss=11727.91 active=34830 feature_norm=196.98\n",
            "Iter 411 time=6.38  loss=11727.84 active=34825 feature_norm=196.98\n",
            "Iter 412 time=6.56  loss=11727.65 active=34824 feature_norm=196.97\n",
            "Iter 413 time=6.49  loss=11727.63 active=34816 feature_norm=196.97\n",
            "Iter 414 time=6.38  loss=11727.38 active=34817 feature_norm=196.97\n",
            "Iter 415 time=6.50  loss=11727.32 active=34810 feature_norm=196.97\n",
            "Iter 416 time=7.19  loss=11727.12 active=34814 feature_norm=196.97\n",
            "Iter 417 time=7.36  loss=11727.10 active=34795 feature_norm=196.97\n",
            "Iter 418 time=6.66  loss=11726.82 active=34798 feature_norm=196.96\n",
            "Iter 419 time=6.59  loss=11726.74 active=34780 feature_norm=196.96\n",
            "Iter 420 time=6.43  loss=11726.57 active=34774 feature_norm=196.96\n",
            "Iter 421 time=6.50  loss=11726.51 active=34769 feature_norm=196.96\n",
            "Iter 422 time=6.40  loss=11726.30 active=34761 feature_norm=196.95\n",
            "Iter 423 time=6.36  loss=11726.20 active=34754 feature_norm=196.95\n",
            "Iter 424 time=6.37  loss=11726.07 active=34759 feature_norm=196.95\n",
            "Iter 425 time=6.46  loss=11726.03 active=34758 feature_norm=196.95\n",
            "Iter 426 time=6.54  loss=11725.82 active=34757 feature_norm=196.95\n",
            "Iter 427 time=6.52  loss=11725.78 active=34750 feature_norm=196.95\n",
            "Iter 428 time=6.66  loss=11725.59 active=34747 feature_norm=196.95\n",
            "Iter 429 time=6.56  loss=11725.57 active=34729 feature_norm=196.95\n",
            "Iter 430 time=6.42  loss=11725.37 active=34733 feature_norm=196.95\n",
            "Iter 431 time=6.49  loss=11725.27 active=34730 feature_norm=196.95\n",
            "Iter 432 time=6.60  loss=11725.15 active=34725 feature_norm=196.95\n",
            "Iter 433 time=6.49  loss=11725.05 active=34729 feature_norm=196.95\n",
            "Iter 434 time=6.51  loss=11724.93 active=34719 feature_norm=196.95\n",
            "Iter 435 time=6.53  loss=11724.78 active=34708 feature_norm=196.95\n",
            "Iter 436 time=6.55  loss=11724.68 active=34708 feature_norm=196.95\n",
            "Iter 437 time=6.49  loss=11724.54 active=34702 feature_norm=196.95\n",
            "Iter 438 time=8.26  loss=11724.43 active=34698 feature_norm=196.95\n",
            "Iter 439 time=6.54  loss=11724.30 active=34696 feature_norm=196.95\n",
            "Iter 440 time=6.58  loss=11724.22 active=34689 feature_norm=196.95\n",
            "Iter 441 time=6.55  loss=11724.16 active=34686 feature_norm=196.95\n",
            "Iter 442 time=6.54  loss=11724.01 active=34688 feature_norm=196.95\n",
            "Iter 443 time=6.53  loss=11723.97 active=34695 feature_norm=196.95\n",
            "Iter 444 time=6.57  loss=11723.80 active=34693 feature_norm=196.95\n",
            "Iter 445 time=6.59  loss=11723.71 active=34693 feature_norm=196.95\n",
            "Iter 446 time=6.51  loss=11723.61 active=34693 feature_norm=196.95\n",
            "Iter 447 time=6.51  loss=11723.55 active=34695 feature_norm=196.95\n",
            "Iter 448 time=6.48  loss=11723.40 active=34692 feature_norm=196.95\n",
            "Iter 449 time=6.49  loss=11723.35 active=34685 feature_norm=196.95\n",
            "Iter 450 time=6.55  loss=11723.20 active=34688 feature_norm=196.94\n",
            "Iter 451 time=6.57  loss=11723.15 active=34691 feature_norm=196.95\n",
            "Iter 452 time=6.68  loss=11723.00 active=34686 feature_norm=196.94\n",
            "Iter 453 time=6.61  loss=11722.95 active=34688 feature_norm=196.94\n",
            "Iter 454 time=6.55  loss=11722.81 active=34690 feature_norm=196.94\n",
            "Iter 455 time=6.53  loss=11722.78 active=34689 feature_norm=196.94\n",
            "Iter 456 time=6.44  loss=11722.62 active=34687 feature_norm=196.94\n",
            "Iter 457 time=6.62  loss=11722.57 active=34683 feature_norm=196.94\n",
            "Iter 458 time=6.58  loss=11722.43 active=34676 feature_norm=196.94\n",
            "Iter 459 time=6.91  loss=11722.40 active=34670 feature_norm=196.94\n",
            "Iter 460 time=7.89  loss=11722.23 active=34666 feature_norm=196.94\n",
            "Iter 461 time=6.54  loss=11722.19 active=34658 feature_norm=196.94\n",
            "Iter 462 time=6.49  loss=11722.05 active=34652 feature_norm=196.94\n",
            "Iter 463 time=6.55  loss=11722.01 active=34647 feature_norm=196.94\n",
            "Iter 464 time=6.70  loss=11721.85 active=34646 feature_norm=196.94\n",
            "Iter 465 time=6.56  loss=11721.82 active=34649 feature_norm=196.94\n",
            "Iter 466 time=6.57  loss=11721.67 active=34649 feature_norm=196.94\n",
            "Iter 467 time=9.82  loss=11721.60 active=34652 feature_norm=196.94\n",
            "Iter 468 time=6.51  loss=11721.55 active=34652 feature_norm=196.94\n",
            "Iter 469 time=6.53  loss=11721.45 active=34645 feature_norm=196.95\n",
            "Iter 470 time=6.57  loss=11721.33 active=34642 feature_norm=196.94\n",
            "Iter 471 time=6.63  loss=11721.28 active=34644 feature_norm=196.95\n",
            "Iter 472 time=6.51  loss=11721.15 active=34641 feature_norm=196.95\n",
            "Iter 473 time=6.47  loss=11721.10 active=34638 feature_norm=196.95\n",
            "Iter 474 time=6.45  loss=11721.00 active=34636 feature_norm=196.95\n",
            "Iter 475 time=6.54  loss=11720.94 active=34633 feature_norm=196.95\n",
            "Iter 476 time=6.57  loss=11720.83 active=34627 feature_norm=196.95\n",
            "Iter 477 time=6.62  loss=11720.78 active=34621 feature_norm=196.95\n",
            "Iter 478 time=6.54  loss=11720.67 active=34621 feature_norm=196.95\n",
            "Iter 479 time=6.58  loss=11720.59 active=34619 feature_norm=196.95\n",
            "Iter 480 time=6.79  loss=11720.51 active=34620 feature_norm=196.95\n",
            "Iter 481 time=8.09  loss=11720.46 active=34619 feature_norm=196.95\n",
            "Iter 482 time=6.51  loss=11720.34 active=34620 feature_norm=196.95\n",
            "Iter 483 time=6.53  loss=11720.28 active=34620 feature_norm=196.95\n",
            "Iter 484 time=6.59  loss=11720.18 active=34617 feature_norm=196.95\n",
            "Iter 485 time=6.59  loss=11720.12 active=34612 feature_norm=196.95\n",
            "Iter 486 time=6.54  loss=11720.01 active=34612 feature_norm=196.95\n",
            "Iter 487 time=6.50  loss=11719.96 active=34610 feature_norm=196.95\n",
            "Iter 488 time=6.54  loss=11719.87 active=34607 feature_norm=196.95\n",
            "Iter 489 time=6.56  loss=11719.83 active=34609 feature_norm=196.96\n",
            "Iter 490 time=6.60  loss=11719.72 active=34608 feature_norm=196.96\n",
            "Iter 491 time=6.51  loss=11719.68 active=34601 feature_norm=196.96\n",
            "Iter 492 time=6.53  loss=11719.57 active=34603 feature_norm=196.96\n",
            "Iter 493 time=6.52  loss=11719.51 active=34612 feature_norm=196.96\n",
            "Iter 494 time=6.57  loss=11719.42 active=34606 feature_norm=196.96\n",
            "Iter 495 time=6.58  loss=11719.37 active=34600 feature_norm=196.96\n",
            "Iter 496 time=6.54  loss=11719.27 active=34596 feature_norm=196.96\n",
            "Iter 497 time=6.52  loss=11719.21 active=34590 feature_norm=196.96\n",
            "Iter 498 time=6.55  loss=11719.11 active=34586 feature_norm=196.96\n",
            "Iter 499 time=6.61  loss=11719.06 active=34580 feature_norm=196.96\n",
            "Iter 500 time=6.54  loss=11718.95 active=34582 feature_norm=196.96\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 2909.637\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 34582 (169881)\n",
            "Number of active attributes: 23106 (154399)\n",
            "Number of active labels: 38 (38)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.030\n",
            "\n",
            "CPU times: user 48min 17s, sys: 19 s, total: 48min 36s\n",
            "Wall time: 48min 24s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#Train a CRF Model\n",
        "crf = CRF(algorithm='lbfgs',\n",
        "          c1=0.1,\n",
        "          c2=0.1,\n",
        "          max_iterations=500,\n",
        "          all_possible_transitions=True,\n",
        "          verbose=True)\n",
        "# Train the CRF model on the supplied training data\n",
        "crf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGU5UwMY24y4"
      },
      "outputs": [],
      "source": [
        "labels = list(crf.classes_)\n",
        "labels.remove('O')\n",
        "labels.remove('B-DMIN')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
        "\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H03Xb0MjnaGp",
        "outputId": "b5f41363-a465-49f2-a889-70ca3791680b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top likely transitions:\n",
            "I-RES  -> I-RES   7.644382\n",
            "I-GOV  -> I-GOV   7.603610\n",
            "I-STORE -> I-STORE 7.562329\n",
            "I-HP   -> I-HP    7.489074\n",
            "I-RP   -> I-RP    7.422316\n",
            "I-MKT  -> I-MKT   7.331117\n",
            "B-RES  -> I-RES   7.315994\n",
            "I-RCT  -> I-RCT   7.267376\n",
            "B-MKT  -> I-MKT   7.193755\n",
            "I-FPLACE -> I-FPLACE 7.179230\n",
            "I-TRAN -> I-TRAN  7.171256\n",
            "B-HP   -> I-HP    7.147498\n",
            "I-BSN  -> I-BSN   7.147008\n",
            "B-BSN  -> I-BSN   7.146017\n",
            "I-ACP  -> I-ACP   7.085294\n",
            "B-ROAD -> I-ROAD  7.046454\n",
            "I-ADMIN -> I-ADMIN 7.039824\n",
            "B-RCT  -> I-RCT   7.032365\n",
            "B-STORE -> I-STORE 7.028306\n",
            "B-RP   -> I-RP    6.971872\n",
            "\n",
            "Top unlikely transitions:\n",
            "I-RT   -> B-ROAD  -1.541919\n",
            "I-RT   -> B-ADMIN -2.013767\n",
            "O      -> I-MON   -2.373073\n",
            "O      -> I-OTHER -2.924190\n",
            "O      -> I-ADMIN -3.236720\n",
            "O      -> I-NAT   -3.429585\n",
            "O      -> I-MKT   -3.449455\n",
            "O      -> I-FPLACE -3.573813\n",
            "O      -> I-HP    -3.720789\n",
            "O      -> I-TRAN  -3.788105\n",
            "O      -> I-GOV   -3.894882\n",
            "O      -> I-DEP   -4.037931\n",
            "O      -> I-ACP   -4.076842\n",
            "O      -> I-STORE -4.094445\n",
            "O      -> I-BSN   -4.108653\n",
            "O      -> I-RES   -4.141079\n",
            "O      -> I-RCT   -4.150727\n",
            "O      -> I-ROAD  -4.220360\n",
            "O      -> I-RP    -4.596644\n",
            "O      -> I-RT    -6.043494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_state_features(state_features):\n",
        "    for (attr, label), weight in state_features:\n",
        "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
        "\n",
        "print(\"Top positive:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common(30))\n",
        "\n",
        "print(\"\\nTop negative:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9zydVHOnbs1",
        "outputId": "c2b36ce8-0f40-4ebc-894e-699fc24ab446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top positive:\n",
            "8.252221 B-ADMIN  word:เชียงใหม่\n",
            "7.714003 B-TRAN   word:สนามบินดอนเมือง\n",
            "7.606032 B-RCT    word:ราชมัง\n",
            "7.386334 B-ACP    word:ม.เกษตร \n",
            "7.156945 B-NAT    word:แม่น้ำเจ้าพระยา\n",
            "7.144025 B-HP     word:โรงพยาบาลเกษมราษฎร์ รามคําแหง\n",
            "7.021909 B-FPLACE word:จ.ชิบะ\n",
            "6.982005 O        word:มุ่งหน้า\n",
            "6.854342 B-RCT    word:ซาฟารี\n",
            "6.719107 B-TRAN   word:ท่าอากาศยานสุวรรณภูมิ\n",
            "6.689090 B-DEP    word:Siam_Paragon\n",
            "6.658530 B-DEP    word:centralwOrld\n",
            "6.534752 B-DEP    word:CentralPlaza Lardprao\n",
            "6.512401 B-ADMIN  word:หัวหิน\n",
            "6.486530 B-DEP    word:ICONSIAM \n",
            "6.453681 B-HP     word:โรงพยาบาลปิยะเวท\n",
            "6.439105 B-MKT    word:จตุจักร\n",
            "6.305431 B-FPLACE word:Berlin\n",
            "6.259327 B-DEP    word:IKEA Bangna\n",
            "6.204556 B-RP     word:วัดทุ่งครุ\n",
            "6.114689 B-FPLACE word:เชียงตุง\n",
            "6.092116 B-ACP    word:Kasetsart University\n",
            "6.085799 B-ACP    word:มศว\n",
            "6.031750 B-RCT    word:อิมแพค\n",
            "6.000830 B-BSN    word:เมืองทองธานี\n",
            "5.952974 B-ADMIN  word:หนองแขม\n",
            "5.950570 B-ADMIN  word:บางแค\n",
            "5.942878 B-ROAD   word:ประชาชื่น\n",
            "5.918649 B-ADMIN  word:กรุงเทพฯ\n",
            "5.915462 B-ROAD   word:สีลม\n",
            "\n",
            "Top negative:\n",
            "-2.797667 O        word:น้อย\n",
            "-2.819002 O        -1:word:📍\n",
            "-2.852535 O        word:พระราม 2\n",
            "-2.859270 O        word:ประเทศญี่ปุ่น\n",
            "-2.867918 O        word:Museum Siam\n",
            "-2.894631 O        -1:word:ช่วง\n",
            "-2.933435 O        word:เซ็นทรัลชิดลม\n",
            "-2.955113 O        word:ลอนดอน\n",
            "-2.977616 O        -1:word:วัง\n",
            "-3.007856 O        -1:word:จรัญสนิทวงศ์\n",
            "-3.033159 O        word:อิมแพค\n",
            "-3.059578 O        word:พารากอน\n",
            "-3.078852 O        word:ราม\n",
            "-3.082434 O        word:ปิ่นเกล้า\n",
            "-3.087476 O        word:รังสิต\n",
            "-3.088542 O        word:เบอลิน\n",
            "-3.132532 O        -1:word:#\n",
            "-3.187500 O        word:ฮ่องกง\n",
            "-3.206692 O        word:ลาดพร้าว\n",
            "-3.237303 O        -1:word:แถว\n",
            "-3.261247 O        -1:word:ติดตั้งแต่\n",
            "-3.294131 O        word:ชลบุรี\n",
            "-3.296077 O        -1:word:ตรงข้าม\n",
            "-3.315084 O        -1:word: ซีคอนสแควร์\n",
            "-3.340383 O        word:กรุงเทพ\n",
            "-3.587491 O        word:บาง\n",
            "-3.589938 O        word:นครปฐม\n",
            "-3.602460 O        word:ราชมัง\n",
            "-4.098138 O        -1:word:มุ่งหน้า\n",
            "-5.746925 O        word:ฯ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGIQZUHz24y4",
        "outputId": "79d3b925-7da7-4d9d-db2c-d73d348c2040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8879567852116683"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "y_pred = crf.predict(X_test)\n",
        "metrics.flat_f1_score(y_test, y_pred,\n",
        "                      average='weighted', labels=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2DHGZOT24y5"
      },
      "outputs": [],
      "source": [
        "def ner_classification_report(y_true, y_pred):\n",
        " \n",
        "    lb = LabelBinarizer()\n",
        "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
        "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
        "    tagset = set(lb.classes_) - {'O','B-DMIN'}\n",
        "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
        "    #tagset = list(sorted(set(lb.classes_)))\n",
        "    #tagset = tagset[:-2]\n",
        "    print(tagset)\n",
        "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
        "    \n",
        "    print(classification_report(\n",
        "        y_true_combined,\n",
        "        y_pred_combined,\n",
        "        labels = [class_indices[cls] for cls in tagset],\n",
        "        target_names = tagset,\n",
        "        digits=4\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_classification_report(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvxFLYQ7m7fT",
        "outputId": "9be37a62-a64d-4dd7-a49a-77643c08e3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B-ACP', 'I-ACP', 'B-ADMIN', 'I-ADMIN', 'B-BSN', 'I-BSN', 'B-DEP', 'I-DEP', 'B-FPLACE', 'I-FPLACE', 'B-GOV', 'I-GOV', 'B-HP', 'I-HP', 'B-MKT', 'I-MKT', 'B-MON', 'I-MON', 'B-NAT', 'I-NAT', 'B-OTHER', 'I-OTHER', 'B-RCT', 'I-RCT', 'B-RES', 'I-RES', 'B-ROAD', 'I-ROAD', 'B-RP', 'I-RP', 'B-RT', 'I-RT', 'B-STORE', 'I-STORE', 'B-TRAN', 'I-TRAN']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-ACP     0.9655    0.7568    0.8485        37\n",
            "       I-ACP     0.9720    0.9905    0.9811       105\n",
            "     B-ADMIN     0.9018    0.8026    0.8493       309\n",
            "     I-ADMIN     0.8077    0.9403    0.8690        67\n",
            "       B-BSN     0.9444    0.6538    0.7727        26\n",
            "       I-BSN     0.9375    0.8929    0.9146        84\n",
            "       B-DEP     0.9737    0.7184    0.8268       103\n",
            "       I-DEP     0.9726    0.8452    0.9045       168\n",
            "    B-FPLACE     0.8246    0.4747    0.6026        99\n",
            "    I-FPLACE     1.0000    0.8519    0.9200        27\n",
            "       B-GOV     0.9444    0.6800    0.7907        25\n",
            "       I-GOV     0.9231    0.9231    0.9231        91\n",
            "        B-HP     1.0000    0.6667    0.8000        24\n",
            "        I-HP     1.0000    0.9643    0.9818        84\n",
            "       B-MKT     0.8750    0.3889    0.5385        18\n",
            "       I-MKT     1.0000    1.0000    1.0000        14\n",
            "       B-MON     0.0000    0.0000    0.0000         2\n",
            "       I-MON     0.0000    0.0000    0.0000         1\n",
            "       B-NAT     1.0000    0.4545    0.6250        11\n",
            "       I-NAT     1.0000    0.5833    0.7368        12\n",
            "     B-OTHER     1.0000    0.3333    0.5000         3\n",
            "     I-OTHER     1.0000    1.0000    1.0000         6\n",
            "       B-RCT     0.9000    0.8182    0.8571        44\n",
            "       I-RCT     0.8977    0.9294    0.9133        85\n",
            "       B-RES     1.0000    0.8000    0.8889        30\n",
            "       I-RES     1.0000    0.8539    0.9212        89\n",
            "      B-ROAD     0.9369    0.6710    0.7820       155\n",
            "      I-ROAD     0.9143    0.9143    0.9143       140\n",
            "        B-RP     1.0000    0.6471    0.7857        51\n",
            "        I-RP     0.9558    1.0000    0.9774       108\n",
            "        B-RT     0.9655    0.8682    0.9143       129\n",
            "        I-RT     0.9435    0.9512    0.9474       492\n",
            "     B-STORE     1.0000    0.7917    0.8837        24\n",
            "     I-STORE     1.0000    0.9310    0.9643        87\n",
            "      B-TRAN     0.9412    0.8205    0.8767        39\n",
            "      I-TRAN     0.9626    0.9717    0.9671       106\n",
            "\n",
            "   micro avg     0.9419    0.8504    0.8938      2895\n",
            "   macro avg     0.9017    0.7469    0.8050      2895\n",
            "weighted avg     0.9411    0.8504    0.8880      2895\n",
            " samples avg     0.0208    0.0208    0.0208      2895\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV1X3Npi24y5"
      },
      "outputs": [],
      "source": [
        "def  chunk_extract(tag_list,sentence_id):\n",
        "  \"\"\"\n",
        "  >>> chunk_extract(['O', 'B-PER', 'I-PER', 'B-ORG', 'O'], 1)\n",
        "  [(1, 1, 3, 'PER'), (1, 3, 4, 'ORG')]\n",
        "  \"\"\"\n",
        "  nes = []\n",
        "  for i, tag in enumerate(tag_list):\n",
        "    if tag[0] == 'B':\n",
        "        ner_type = tag[2:]\n",
        "        if i < len(tag_list)-1:  \n",
        "            current = i + 1\n",
        "            if tag_list[current] == 'O':\n",
        "                nes.append((sentence_id,i,i, ner_type)) \n",
        "            elif tag_list[current] == 'I-{}'.format(ner_type):    \n",
        "                while tag_list[current] == 'I-{}'.format(ner_type) and current < (len(tag_list)-1):\n",
        "                    current += 1\n",
        "                nes.append((sentence_id,i, current, ner_type))\n",
        "        else:\n",
        "            nes.append((sentence_id,i,i, ner_type))\n",
        "  return nes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ir5TsDb24y5"
      },
      "outputs": [],
      "source": [
        "sentence_id = [x for x in range(len(y_test))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo7kXolh24y5",
        "outputId": "c2d39f46-17d1-4d5b-d2eb-3db6fb926f50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5617it [00:00, 212223.95it/s]\n"
          ]
        }
      ],
      "source": [
        "chunk_test = set()\n",
        "error_id = []\n",
        "for sent,idx in tqdm(zip(y_test,sentence_id)):\n",
        "    ch = chunk_extract(sent,idx)\n",
        "    chunk_test.update(ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrvlJIie24y5",
        "outputId": "447da306-01c8-4cb4-e031-168cb584cbba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5617it [00:00, 176649.61it/s]\n"
          ]
        }
      ],
      "source": [
        "chunk_pred = set()\n",
        "error_id = []\n",
        "for sent,idx in tqdm(zip(y_pred,sentence_id)):\n",
        "    ch = chunk_extract(sent,idx)\n",
        "    chunk_pred.update(ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxxLpE0R24y6"
      },
      "outputs": [],
      "source": [
        "def evaluation_phrase(true,prediction):\n",
        "    total_correct = len(true.intersection(prediction))\n",
        "    total_predict = len(prediction)\n",
        "    total_true = len(true)\n",
        "    \n",
        "    precision = total_correct/total_predict\n",
        "    recall = total_correct/total_true\n",
        "    f1 = (2 * precision * recall)/(precision + recall)\n",
        "    \n",
        "    print('total_correct:',total_correct,':','total_predict:',total_predict,':','total_true:',total_true)\n",
        "    print('precision:', round(precision,3))\n",
        "    print('recall:', round(recall,3))\n",
        "    print('f1:', round(f1,3))\n",
        "    return [round(precision,3),round(recall,3),round(f1,3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xo605af24y6",
        "outputId": "aa0d86d0-60c6-4f38-d48b-0f9bb8a7e969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_correct: 801 : total_predict: 880 : total_true: 1129\n",
            "precision: 0.91\n",
            "recall: 0.709\n",
            "f1: 0.797\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.91, 0.709, 0.797]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "evaluation_phrase(chunk_test,chunk_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prIDivXO24y6"
      },
      "outputs": [],
      "source": [
        "def evaluation_phrase_type(chunk_test,chunk_pred):\n",
        "    total_pred, total_true, total_correct = 0, 0, 0\n",
        "    df = pd.DataFrame(columns=['PRECISION','RECALL','F1','SUPPORT'])\n",
        "    ent_types = ['ACP','ADMIN','BSN','DEP','FPLACE','GOV','HP','MKT','MON','NAT','OTHER','RCT','RES','ROAD','RP','RT','STORE','TRAN']\n",
        "    list_correct = []\n",
        "    for ent in ent_types:\n",
        "        true_set = []\n",
        "        pred_set = []\n",
        "        type_pred,type_true,type_correct = 0,0,0\n",
        "        for tag in chunk_test:\n",
        "            if tag[3] == ent:\n",
        "                true_set.append(tag)\n",
        "            if ent in tag:\n",
        "                type_true+=1\n",
        "                tag_true = set(true_set)\n",
        "        for tag2 in chunk_pred:\n",
        "            if tag2[3] == ent:\n",
        "                pred_set.append(tag2)\n",
        "            if ent in tag2:\n",
        "                type_pred+=1\n",
        "                tag_pred = set(pred_set)\n",
        "        type_correct=len(tag_true.intersection(tag_pred))\n",
        "        try:\n",
        "            precision = type_correct/type_pred\n",
        "        except:\n",
        "            precision = 0\n",
        "        recall = type_correct/type_true\n",
        "        try:\n",
        "            f1 = (2 * precision * recall) / (precision + recall)\n",
        "        except:\n",
        "            f1 = 0\n",
        "        list_correct.append([type_true,type_pred,type_correct,ent])\n",
        "        df.loc[ent] = [round(precision,3), round(recall,3), round(f1,3), str(type_true)]\n",
        "\n",
        "    #Calculate micro macro f1\n",
        "    total_true,total_pred,total_correct = 0,0,0\n",
        "    for p in list_correct:\n",
        "        total_true+=p[0]\n",
        "        total_pred+=p[1]\n",
        "        total_correct+=p[2]\n",
        "    precision_micro = total_correct / total_pred\n",
        "    recall_micro = total_correct / total_true\n",
        "    f1_micro = (2 * precision_micro * recall_micro) / (precision_micro + recall_micro)\n",
        "    df.loc['MACRO'] = [round(df.PRECISION.mean(),3), round(df.RECALL.mean(),3), round(df.F1.mean(),3), str(total_true)]\n",
        "    df.loc['MICRO'] = [round(precision_micro,3), round(recall_micro,3), round(f1_micro,3), str(total_true)]\n",
        "\n",
        "    print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbLSLImg24y6"
      },
      "outputs": [],
      "source": [
        "chunk_test = list(chunk_test)\n",
        "chunk_pred = list(chunk_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unxtfm5R24y6",
        "outputId": "a6dc8c61-54e8-426c-aa42-f3596b4b2c27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        PRECISION  RECALL     F1 SUPPORT\n",
            "ACP         0.931   0.730  0.818      37\n",
            "ADMIN       0.898   0.799  0.846     309\n",
            "BSN         0.833   0.577  0.682      26\n",
            "DEP         0.947   0.699  0.804     103\n",
            "FPLACE      0.825   0.475  0.603      99\n",
            "GOV         0.889   0.640  0.744      25\n",
            "HP          1.000   0.667  0.800      24\n",
            "MKT         0.875   0.389  0.538      18\n",
            "MON         0.000   0.000  0.000       2\n",
            "NAT         1.000   0.455  0.625      11\n",
            "OTHER       1.000   0.333  0.500       3\n",
            "RCT         0.875   0.795  0.833      44\n",
            "RES         0.958   0.767  0.852      30\n",
            "ROAD        0.937   0.671  0.782     155\n",
            "RP          0.909   0.588  0.714      51\n",
            "RT          0.931   0.837  0.882     129\n",
            "STORE       0.947   0.750  0.837      24\n",
            "TRAN        0.882   0.769  0.822      39\n",
            "MACRO       0.869   0.608  0.705    1129\n",
            "MICRO       0.910   0.709  0.797    1129\n"
          ]
        }
      ],
      "source": [
        "evaluation_phrase_type(chunk_test,chunk_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDThlkAV24y6"
      },
      "outputs": [],
      "source": [
        "#save model\n",
        "with open('/content/drive/MyDrive/dissertation/TEXT DATA/TrainingData/3.Model/1.16CRF_pythainlp.model', 'wb') as model:\n",
        "    pickle.dump(crf,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctdfT3zA24y7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}